{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "W8qiZb7wC82Z",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:03.626154Z",
     "start_time": "2024-11-29T20:59:02.193548Z"
    }
   },
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction to tensors\n",
    "\n",
    "### Creating Tensors\n",
    "\n",
    "PyTorch tensors are created using `torch.Tensor()`\n",
    "\n",
    "Docs for this:\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.tensor.html"
   ],
   "metadata": {
    "id": "IQU2C6hcq3hq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n"
   ],
   "metadata": {
    "id": "PnHgf42Btnzu",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:17.141429Z",
     "start_time": "2024-11-29T20:59:17.139666Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image of a Tensor\n",
    "\n",
    "*from* https://www.avni.sh/posts/linear-algebra/tensors/tensors-cover.png\n",
    "\n",
    "**In the picture we can see**\n",
    "1. A row or column vector (with a dimension=1),\n",
    "2. A 3x3 matrix (with a dimension=2)\n",
    "3. A matrix of matrices (dimension=3)\n",
    "\n",
    "**Note** <u>Even a zero dimension object can be a tensor</u>\n",
    "\n",
    "*from the website*:\n",
    "> \"In linear algebra, a tensor is an array of data expanding in multiple (or zero) independent dimensions. It is used to represent quantities/equations/functions with multiple components, for example, the equation\n",
    "\n",
    "> $3x+2y=0$ could be represented with the tensor\n",
    "\n",
    "> $[3,2,0]$ where each value in the tensor represents the different components of the equation.\n",
    "\n",
    "> The number of independent dimensions of a tensor is called its rank.\n",
    "\n",
    "> Vectors and matrices could be generalized with the term tensor. The following Venn diagram visualizes the connection between them.\n",
    "\""
   ],
   "metadata": {
    "id": "o8h2V0MnwGL5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "image_url = \"https://www.avni.sh/posts/linear-algebra/tensors/tensors-cover.png\"\n",
    "display(Image(url=image_url, width=800))"
   ],
   "metadata": {
    "id": "RzhKcxwytnwb",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:23.324020Z",
     "start_time": "2024-11-29T20:59:23.320311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.avni.sh/posts/linear-algebra/tensors/tensors-cover.png\" width=\"800\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "`torch.tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False) â†’ Tensor`"
   ],
   "metadata": {
    "id": "lybNZcz-0TMh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "scaler = torch.tensor(7)\n",
    "print(scaler)\n",
    "scaler.dtype"
   ],
   "metadata": {
    "id": "i-eI4jhIqpWs",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:25.523821Z",
     "start_time": "2024-11-29T20:59:25.513174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "**As per above we have a 0-dim tensor**"
   ],
   "metadata": {
    "id": "c5UXa3Xp0-sJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "scaler.ndim"
   ],
   "metadata": {
    "id": "S1tua_PSrN_H",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:27.081363Z",
     "start_time": "2024-11-29T20:59:27.078978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# Get tensor back as Python int\n",
    "scaler.item()"
   ],
   "metadata": {
    "id": "AlFfd1DP0oq9",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:29.073694Z",
     "start_time": "2024-11-29T20:59:29.071089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ],
   "metadata": {
    "id": "Jxytrsgy1LMY",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:29.985988Z",
     "start_time": "2024-11-29T20:59:29.982216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Vector Image**"
   ],
   "metadata": {
    "id": "jFLBiDzO1rte"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "image_url = image_url = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAQMAAADCCAMAAAB6zFdcAAACRlBMVEX///8AAAAAAP/8/PzBwcG3t7ff39//AAD4+P/8/P/p6f/19f/s7P/09P/x8f+MjP+IiP/i4v/Ly//Dw/+Pj/9SUv+8vP+Cgv+YmP+xsf+cnP90dP+Li/9CQv8qD16Skv9paf+pqf+kpP/Nzf+urv9+fv/AwP/z8/Nvb/9YWP+2tv/f3//a2v9MTP/U1P85Of8qKv94eP9iYv//399kZP8nJ/9ERP88PP9NTf9jY2NXV/+Dg4MVFf9kZGRSUlKYmJioqKiGhobS0tI+Pj7/7u4jAFoAAE9GRkYxMTFxcXH/w8P/sLASEhIkJCTY2Nj/Ozv/l5f/YGD/ISH/cXH/jo7/goI0HWXJAADDv8n/19f/Rkb/bm7/Kyv/UVH/lJSemK5YS3tDM2v++evBpKhjVlphPmBYSlwtBgCGd6TPZVQ2CySiq5gwGyNGVj9sQEtMPXV6U1BGOmRKTo1UZZ1CR5drg5iHdoe5xqhWZpEsUMQdRMIAOMwAV+Uqcd9XdswfOmBGLjSnnb7XwMDKOC7Zkop6aWhjVXsAJrNBkfMAbfkOeuI/Zn6NgqaRED3PbWkkLHBoh4VyEktIM0kAABYQDnIto+oOdPMQMD4IG54dWe6Gs+Y2WqEUDivKFhiwACVfAE0pKUQZEKNCXLtniM1mu9mMWXdYJiUSAHgkO5BLFwCVLzekn9e8YWtvADVUyvkREAAyUlUyGkgVKMwXlu2o8vi2NkBi4Pp1jNqyeIiLABHx8bL/9JFGobwALdIhMJycDzZKD1cAAEGyykMCAAAgAElEQVR4nO19iX8bx5Xm6wIJoXE2GkcDDUIAGvfZAEQABNEEwQM8LFK2ZIumD0WU7c0om8xq1sl4bMvKjLKJPUrkeGzLHs/sOvFkNjOzu7PRrrObnT28O/nP9lWDJBokTgKUfPD78UB3V7+u+urVq/eqqgsAZ+iGePxSPP64M3EqiMf1w5Qsfn3v/FpzrXnjvv7wlO408/XI8NLLr/wLZvPbf/DKywMSXm8idnaaN280127uU/adr4VSvPwvme9Of6+x9IfTzL+a7pNOf6t5/nxz58atG3s7+KG5S0/+/DuPKJenCfaPNhbr//rV7//g+z/4Y2aaea1nQv0OUnDrxq2dHWSAYm0XdN959sIjzOspQfe9P1m49fobb97+q7fu3fnhn9b+bKVXyr3m+Z27ezfv7jWbt1QWmg9+9G+e/fGjzOwp4ScbK2+/+s6bb97+87fu3PvpT3/2SmOxe8LrzfPN+zdu3Vy7f7/ZbCnCu88++/NHm9vJw4C2YH339fdu337zjTfeunPn448/vvcX15nlbmnj1Bbcv9XcOd+8cVfl4P1PP/3qU0DxwYefvfcAteD2W/fufXzno4/v/fQvF7/dLeF1ysGt+7T0zfN3d5rv/+LZT5999+aQj4k3hus9uvfP8Rb63BIfo4fe3fzuqw8++eT2W2+98Vcf3/lr9s/v3fm33/13+i4p36bdYhM1ABtC8/zLnz776S8+/WXz/HBFW2AYpjZMwi2m29k6o6LrHTpmGyk4cnF6aqhstfAa89mrD/7mV7964/Ybv/rbex//+3sff/xDhuliEXQ7Tathx3j3xl3Y/eUvnruw+uv3f756t7nWja5jWGfqNYa5NETKxc1uZzdrGyihu53SMUwcppnOQjMbw2RrH3/38O0Hv2/+/T+8+rfX/8N//E93sDnce+NnzE+OJ4w316ywe+m9+9gffvqPsHvzH/+zBaxra7tDPGSawZI1MJv6pSoWZGppuroYr9Xi0FicrjewGI3Nmp6erseXpuK16aU6Mqvf3NTXDmlbwHqOIwuNmu5SbRmmqrVDR2YTOdjGMjeWlvRUeHUKlpitKVje3GzQs9ML+x97gdl6/aOPfvPRH3/IrC//5IMfYnu499brD/8ADOxRDtbWjFaAT3/+0gW4v7Z74Tv6PaMF9obigGGwseriMEUVugG1lmYzS7BN/02hmuAHPL3F6JnFZXpuhWo3Hh+2tCoVgacxXZVpSTjQwE1Gp0dZCyhkvfUIem9juiW7vsJsLDMbW0zv1sE83Hvni9u//c3vfvaH/+XSf73z1lt33rr9s4d/dzwh21xbxU7gl/fhLujPv4uaYN7dhd3fd+1DjtB3oJkbW3E9fsZMLjDTOqYOzLZ+illYRl62GTzd0C0y+hoeYWFqzNQUs607FFGnma1P0QLW4symrnHYYDcZSsMlPN5AIVt4sLyMXRtTjy+j/lEeqtug78vB5oPPKxX5t//tL5ilm2ga37z9xusPV7rowbu/2L1xf/fG3bu7d3f/+693757fvbW3e3dnCHuwjLVEQbOpFnaB6m+caegZVGimimq/TXNbRXPAxGtY48gBJlLPtKCjh1is6gp6snFkClk5sLFLSMsims3qpqpHoJuiLUe1EMgDfeYGwyz0yecfMa/8yXuf52//9W9/92fr/+PNN5GDH3zWxV9e/fFrzRbWbv7T/1T/3791a29tZ4guiVYHNuapGqp2nCp7A6obNJMNrC6ssiVmpdY6TW0Z1riOWbyER3Hm0EA26EWgKs7Ut1WLN31oYpcZKhiNZr1aXWq1njpDf2jl00eArt6rU1Fxndn6X//7pZcuffHFR/+n/it0E26/8/rDrnqzu0Ydg/M3zr/7T2bqI+zd3du537w+mALM5FYcq2ZqCeWqKk4VFQuhb6i2II51jIRQ/VVb/BI26ukpLH+tnY+G+hGr8xLVbSqvbSuwfdRpXaNpvUTZ2FqgSlRFXanSR2CnsaXDx/TO3yp2hLqX7n+R9d/+HXrM77zzzv999eHW0Yag4kbz1t75nX/+f/9MvUV0Fm/u3Wo2h+oaV6h5q2JbYKpq7lDZa7SiUEfrzGacWaliM6fmHWsfy48tYhlUq3lo+zfUIjCUqW3aYrbX29em1F53gVnfZtC6bKyoN09RZlSrSwlcr6ptqRfqzIfVD9c+/+IL+Tev/v07n3zy4PufdXMPgCpC88be++/S8u/s3Nrbu3t+b2cYNcB2sM5sNYBmZgstw2JVN1VdhsUlWFlZwhrAItUXF+KNahz01alL9BLageXNpc123S2pRcBUlxaooE1mvR3jxxeoudGvMCt60FVprwhU4xaZDSxHjd64RCu6X/6YrQ/Wf//gnc8//+gHDx78zYPX//Lh93okvb7WfPf98zeaN2jQeGOPtoehKOgF/b6t7IbGEui21scSPwKmmYcrr3/2+08+v/MPzQc7r2NP+qNeSV/DdnDz/D6ab6/dGm8U7RLTe8BmE1tP99jtVLDIbD389ts33vvhjR98/4MP+1Dwox+jJpw/5GDt5pgDidO13sFGfHGp9ugooHabee3DD769Xt9+2GA+62nldEiO/ubaQRe5N4yH+NXB6vVXmK1F5pXXmO81BqXV7958+9bbN68P1SF8ZWCgf3YbP3nl1y8PE9l98zB1BmDOALozPO6meIYznOEMX1bo673de4NjGAmYKp0Ac1h7bqpxPN1SO1JYjsPmQJf08io80TbfTz3RM6GmBJjqySNXn7sAV5/r/6T6eo+JSISZ9L/3MJUlDHxWe67RZeql3h7HWlmGrYEcIAHn2hw8fbFnwvY4NU11lCs89dxq3wfpmPh2+0gxglOChBwASFb8ME9EcMoJsJJKSr3OyfN5ECIQjEHUlbcASZRS4CJSOgt54pjlwbTPWmOlXtXB4jqWdHNlo1WSan2Fjq9ubGJgvwEbCxuNVtpnLr949ckrq3Dx+XMX4Ilzl8+tPvEk/oEXV586dxnOge4crF558vmLcPHFy/uFia+v1GBqpbpFh9SqBxy0Up2Dp66dgyeev/YcPHfuykX81b3wBDz1JN577ukr3bRpehM22vGEIAIx25xQdEeCIKatBLxJEJwmkjPRy7kSRAgUQnidDUACE7OYBPUglwd+HjIEIol9DhagtghL0NjUMzDdekC1BgvT01WoLcH6MmwvH9Tf1acw389chWfgIhZ59QJy8Dw8dRWQEdQDlYNrF+HFixeuwBPXWuKX6c1T67C4hHWoP+BATUU5eH5Vd063eg4lrD4DVy/C5SeeeBKeehov4cnjqC9O1dp6m8kb8zCXLea5Aq14o1pgPmvYr11JoAWOhmDWDYIsS0AALxlVDhwugAqv8Psc1GBxEeu8vglLzEIrj9gWpmu1BiyvqxzoDzlQ8/0MPPXitadpHpGDy3DxaZWD1RYH+P/qxYtXLl/bL4K+uo4cVCnFG+22oKaisr6FGnD58rkLauqnKQd4CinszkGcmZqe1gzO5mc9UIyBwcqJYLdg6QIBSAUPOHAXaV37IlB2iEXwdXIwD5AmedBwMLWNmYwvwnRrMqY+jeeQmemFrhw8dwUuvrDPwbUDDnStfF+5AJcvUiXYXx1DR6FbHMS32hyoqVp80uJfoMKea3GA4lC5unOgToautI0VqjrYiUdJGYhAjGbiMJTwv/XANuYLJQWVhSu5cySqFJEDE20LjowCYZIDmPcccID1vxRnatvbOmZppWV163TGIL5dY/RQrwJz6SDvT9O28K2rq+euXrkCzzx/TW0LF19QOfgWXL18FVv3uafPXYRrL1y+3BJfW68zU1N1+pjNev2Ag1YqtV3B1WtPP0k16wX8BNewt7h67rkWB888dVQP6O36tl01penfDLZ+S9qKjcGIBwCsff8ym04jHRar2QTGNNgBU6dpKpqApif2tlz6owc9/tEfnFMfRI2DDi/o6A/F6ipWL/5ZvYBVdxGb8qpuVT2po6fwGv5ZvYAn4MLhIil9a+UCzb4+rj/oPdRUqixQb1Vv0F3QqffqqCjd/tWxYOzXXSq+ccXrXnj+yWfGFXKGM5zhDGc4wxnOcIYznOEMpw7WnqaR4BGkH0NO+sOaTmeOLTYzGSci205EZ+7YWbL/OI/HaFeOUzQQDkmUjp3MHQxJGwxg7bp4rg88FY/t2D0O//6HqGCUy4YRRR7CjkGy1QWyZdZlSgiuSDY8LySBAF9OAThLJb9ATsBBUsxkjp0McK3/lkJQCMojSvUEALwheyGdjVqLvuhM0VFIBsIu8JTNAFlFka3ZEyuFnRSz4CUOcEeT+ZxPjHDEwoWIleSICSAYRJ04AQdFT87sk6Kis5j0kjl5ljhL+RkpYKzIGTAq+awE8nHl6wuxlOSgWLHYeWWGYJ78MzKUpKRD5mWAzIwE0uHAzsigegBCWeSTYjBvTLhD+ATRQ4zEK7CQL5VCJ+MgGsqBPAsZJ7EFLZhnmwd/Rd+sIIAlUPCayKjDMB46fJcv2xPirFNBPa3Y5kD2JFNyRAJeKZWjFoEbPZ8tGMl8NlQC4s4HXHljIRYJEJ/CEgj5gyyEbZGT6UEyxbL8fN5O0siBGTlwFo1KICAmUm5wKHmxHIIRDYKUd2VFLpyIuqJBGTlwBWTXbK4IwQpmMWozZfJ58+j57IWhJp0GIFTwRUMZPiWKoidkEaAQ8PnCDjcrCthoJQmEaOK4vRgNjrnR0sc3R3ij1z2a7OEwY5u0xM6Jz8HQM497MR47al84cTx+Dh4/zjg444BiVA5G9F++EhiNA7YcPY1MeC0TFugYyTEciQO+RE7scfXBLDlxTNMdhdGc41E4SBByChzkUOpEObArRMNBWBx4w/AcGEvkNDiQyIQ5SFGBhxxIZJIcpJOnwYGfTJgDNZcHHNizZKIcADhPgQN7csIcGBNtDtz042Q5IF4PEU6cuR4wkdKE7QEVqHKgNrPJciDRcaWh1myOgkIWOGKaoMCAggrb0oNwfsIcsMQ7Rs56wUoXMZknGDYZSAzAsi8wN2EOQpMYPTiGaGXCAkVFc5CctSYDA28ZmgMzOQ032UzGHTA5CqJprTky1GDq0BwkXCfJ0SDIk7axyVnNQTY41D3DcmCceIVR8CcZkeyHtLbm00O6zMNy4CufJEuDIBcmLLCY1BwMYQ5VDMmB/VTUwEEmHDBmtDU/tBHvwwFrpmjlcjbZK9U4yE/aGswXNQfk+Jxed/ThwOyLRqOFCP0Ym5wnx3sREbX/jkxEalgVqNoVB9FMJKSG7suHawulyVVYLuZwOGIqByQyCYEZVaDqaRKtLzC89L4cGPeNwATVQAPPpJ0ur1agWBra+ezHgSGZaIWJpUlOgxg9rbc8WJKajECrJ9b6oGj6AesILl1fPYgWVU+Wn+wYR5io6zikSamBI0zUiSW3VqAgDy+gHwdiMkTfSmHJROfYuIKsZnliUqWiSxWl7QdG8sH7ccCGchG0NU6lZ4qTgHgUmuVicWDKIaFwFVr6qLbmRwrFBvcLajCqwbhxrslsNVOn68TrIo7CYLSgQAvh26esZJRp18EciJ3tVgqNIL03Jh6C2fKag9F88IEcsNpgFEyJyYykDBvODA2Lth8Y0QcfyIHg1xzEFDIZDoqTVgNBqwb50WbDBnHQEYwG6BjlJDjocGongZxWr8IjRuSDONAGo04yKQ6UmQkI0aJjtCQ/4gTAAA4yHaNRdv9kOPBO2kvuGItJjRqRD+BgvrMXJ76JcKAMHuccDRXNer7Rx7/7cxDrbFkRgh3D+MFejAzwMSLeiJ0dYZ1STmteRvfB+3PQEYyi5zER99YwUIw6XUacQ0vUeskn8Oz7chDppHSUOKQPOrqxrjCpHAytBx1e3AlCsb4cKB2DkuaRHNCeMJHB83W+oeaHDkA0rqvxBNMg/Tg4Mhrl8/dINxqcpUEpcjJSMLzOdYydBk/gfPXjoHNQkp/MILBBG9t0Q1gmgik7gs5p+4EThWJ9OCh0VsWE5gIK/SvKgQwg17nh43WnNptBdamy3+VyzQWHltCbA2tnhU1oSijT10sOV0i09Zihh0A6RksOp0FGCvB7c8AdUYPJrECZD/a+hnagMHJ7K2h3ZUruu3TOkTLbkwNLp4Gd0CBwrrca8DLhRlc1I9G8ZJY66E/FYHIEL6EnB0d68cnMBUDPVrpvB0ZGxzyocuBWeWbZ4d2Lnhwcmbqf0CBwpseCAOwLoicyNx3ugPuw3B4ORljf04uDcqLzUZOZcu0+BZjLk+gJ+92OCTDlYF8iECujxM89ODjSCxQnM+XaVZuwFdhO6nl0TIA5RlD/DvTgoNLxcpna/5gLgiBEx5ob6qIGyAB3ct+rpKlt04kjuu4chDvNd4VqnHYq/mSIHFMDagfGkOjQqoFtoA/eC905kDsGJfmTKtkRkCPD8uE8esXjCCxpwmvDEKFYD3Tl4MiUwoGtCYxnGANyB5WOPHFawOzged5xsndxO9YvBE6sBt056KywQ43LxsZ56b1z7gcZ4KgO2EORSCR0InI7xmIGhmJ90I2DTvNtOozLkknX8EH9MRQ03gyPveHY63M92rhqnPGdLhwcGZRsP2ouZzm5q6RZEIAMaPoCbvgxsw50zIP2D8UGoAsHjqC23bJtJcv6nImjiYeG76CiYmgHtDoQSARPZM0C2vqYH2cWe/BcW1uFHeHQiRdjsKGW3TuwA20EZq0n0q6QZrRkyEW5PTDSXNvYoHbgKI0BJ4y9zsUfHOfuUebaxgUy0MUrduZL4w5NmH1jVdQADsKTU4NYiThPY3nb+BjAwQRfSj9qB748eHTvO094hfoEcfbO9xkHFGccaDmg5m8YE6gmMUC3MfzHvqvHydDmgE7tKPs+fbpPj017Swt6NYn9QSG2PXHUZaIrZhjqeyyM9ME5c7dtZ4ydk6i8FdghBozUfWEydjUDR2A9Oo2naQsVs7kCIR9Yo5JAeGPQyxY8LDgS6hPNiQAbFZ0Q8KgeA+eGEsSCZoNnJkRCJkGEGTENSsB3tP8rRiAU3P+s9A6RvTSN5IPMQYDmOwzfvZ2hgBCA2IH7PtebXZ5OELuz7V3BA4frzvmjIaaGg0g06vUm3dEy7w6VgZhdKRJi6RJrWug0LweImaQqVvUwU0r57CTnt3nCMQJZR8Cj2MyguMWjq+KMfshbUhUOgjJHZENSDjvLTjD7/epQRNEVsSVlr7s0r05mEhAcuXISnHK0VLIm5JADD9xyVhupsQSKab6SwCBMUPKm2bwjlC2AoexX1aUw75FcFTGsJFX/tsRKIbvLBSE5IStGQbZl5DLgxY5vDOmwibIMgitAh0z4OcyPc4ZyWPaqhRYTBSfd2EuAlufoKptTJY80r37xBrE4goqRNpPwsVe/KqEyBuOyJwEW2c6JLJmhUWMkGaQX3QHCSSmBGCR1DLcgEVA8QWcejELKkUS9KlohNQ+KduwmSffuCrkCLrAWwxLmx0kn6LxB9ckOkdi48Kxsj6ktNCASKHNRLIjR48lUQPb4zRCWwd/RHLQcJBJgrsheRynvJg6pVFHjOWJTB+qC/tkkFtZMgi0OIqi05XLUni+5iYfPy0ZqC8j88XmIFHFj+M155yGXt3tsVoVDO+IRArRu06Uw4bxeQTGrh2AnHORDYkwBR9Sb84Mi4ulUBTocdp5IQNwBtwzh+XAqCIRquTcYonVrpjuQefiiK+dVJ6BNJAjJgISq6nB6jCUoSZgqrECpI5un3zdW8KnZAOvx85IfOJddQvvCz4VoxVtdoaTgcEjhstAaoAoawV6MWlJlifebRb8jHMC0BZenQ2DWABkXx0rllNtvCPgzKTQdmWyIjnoYiigwlZtJl/e3iRMyYEwkzLzfk/PbQ2VvGttqJlHsfDXpzD8444CizYF52MVM4XRHSn7SG/s8crQ5cA+7mikval7xIpDouwJo5mRjnVImve908kccInHIBUdGj9TuTaxGY5+R2zYHsfx8wiwnRc5YdlTUNdV8uZTh5sVQ0h+dnzXNllXrnC2WPELENRPwp6zFMke4oj0sF1ni675RI8mYgTWCGUNntpXAYDSA2QpmA/5iVlt5NJjVAxYMVosJD0JpkjOxBhNYRaFziwiZOopGsLIWlm3dzKJAK95/KIPCnMuH7FYDmOh3yoA4a/TQ/wZDt+0mNBxkTXSPTB+RCiRVovnNi6KFl4gtmpNZ4gyKBZUXyNuCUtRB3AoXYi0ESnbCih5i8HddSabMklyRCxJD1lNO0sFwsyzk08UsTwokofAJn6p9pKjMViSOq7AkSjjiqwQlJDcm2rh5OSAWyxrvc24+7/bZksSecFZm6cIQi+wkxnmXgwSVoOy1BbO0lDGlWHZlCBHnXBkuKbvkSB6UYNBNEl1edNJwkLQSTix4XEqOONR5wJwj6aQdbiA8ZyBi0Eu1MieDMjMrBeyEdzpFq13lwGpD50buygGxJmJuH7HNEG4uQUnMlNEN9vlteKMxymGRqT9PLEGH5Mz4iOCDii1hUhJhxTTrkNC5Cc2QgnaXWX/GFuJRoI3Y/IV5PGEs+0QQ5qIE5nMeFFiijSWfNlaSGQKuZJFDL8cr2CveAihcwdxlwVubgzBnSbqzEoddKF9WNywOuBJsUXJFI5moIctGk6pj4QsGQzbskqVsyFBwZQqCz57JCiCDr2s0QIxBjmSIlUipopvO3WREXkGVQg6wKkNKuECfRMxY6Rzy7SA5MlM0k1mehPHRgYrD5fS7ZzQ+kpzjOGInRsKF/Q4athkDGSJwTiQzG3Z68rxAB6y4GY/syhFTIBpxlHguUAznjSSnhIL2LuP4p903SqZYOsSL5ogV/Vg1hPN4rHZPOCRCyOpIWwO5Viq3PReOpbwZKVVyxwyhmD0s2j2xMP7y4NGGRl4zn0vFpLTbCOGA2kYkj9FMBbIpYzjHBtQpIdYT86bM+MBUiGUDYZOHj0AmYE3HLF1eSfuy+QfJymnsStcfXzYOHgfaHFg6ZhLYNPZfGYN9mO7d0O6yv3w70g+B4z5SVG19BuKMuWVH50LNTPeZzUwyduCBHLM4of0h9ZYz6eAlcETSnTHQwYZOGV5sj/kY2Ezn67XHIQ09X2GR4CCt2GWaR9M3+pOBjGBwKSUTmLJREonk81mSEstGoRBzzrFJIelTX9ePRec8wQKbnDeEy1FxVnCFnUGCcWAF5gUCM9kO33k/7N03xwWPE7uDSqddOhjASyVm2hlMhHKDXksafgrMYnMcjJp0W3Wt4UDdqd1Eosg/JxqJkPJydn9GCftdEpd0J4g96VQlhVxG7NjAHSzIdvSn7EUu6xbseSASZyIhl3teK7+E3gyxBxW6tKXozzsVicwq2ZicjZFSqDIrKeWyorot+In2ecRdqUCwMpeXAz6TXEpx+Xzne4B8xZ8j6HPhL22nkSzhE8GEqPjLyZK1onoSMTKfDxJr3h/jSXZOdpGQ4iQhuh09vclfObq2TusnguzBrtmHHBRCVuQgImQqjpJXymZEVyhG2PmZFgfRNBbYmwgIijVSIIakLesV0jIQjwcIpvTaNf4oMYeTeWOBrhZCXYhStwDKdmJLci6WiBVOsGfnVMeCQCqKHAD6hxySIqRSUU4CYpMcsx0ZNgXyVAgngMpB0Oe0hDl0mTJlPJnk6LCEI8liCoNUxCfn5v12YUbJFQ14asYGxFnxHH0Xpc2Bwz8XtCoJOYJtwawkSjNu70w6iy5dJJkzBCu8YphNlah+erk0Ps8tO5O8XCyUTMFAMq248z7ClnyEptSuCSFu0alkZDosZyJWWeVAzlQiooQy0HkRMmW/aoDksKByUA6JPDFKUclbSAUz+RnJHQxpG37ZW6RCUn6z2hZS4aITb5uZyflZEpl1q43VRffzDySkpM8rJeV0gSP8HCYnqTn8zfOSt9PSj9U3hjyuQY3WKfnYVFQK2zCh2ye5OfCBx24VpJwIRl+KTxlFR5AmzPiklGCOgpUT2VzCkfGhVxkqWN18xtuxhDFWiHkEiBo8HtUhdBc84ExxnphdhAKqqDrgKxkwRbqA/qUQyIpmr3sGfLxHjLJOUTC4E3ZbpyUZzz/gv+R9IRqXId4J+pr7SEPNfH3NORgK32wO1qeQgG84B8DQr1f+hnOwuL45ZFv4is6pDwNGNyQH2cFJRoflS9Gv0m8I7/lOF8VB36qGi96Ez+cLTm47G8dkNhkaE+q3nPfgICIh9lepe1vRtMFgsVjGahYZzul0zuwzW6BunkF9LffkXyGlCuxYhVChAkdbVj14fyQWiq0lOpmxX/03pe12+8F3Ac73TzsUDKrAcffY6cmB0dV6rctFt2NQIy1xchtJmhy8x8mrodCI3yfVA6z6OoxKxuzICyF7cmB2VNThnpzDF3KoGiDJ+bG/0X7Opep9Rt3oohUzG8d6QyiYVPXerApUGwXJjLoLRE8OnEJBNQcmw7zJqgZuUhTG3trJzbUGlFirb7/HJZwyThvjA60XWln2YBMZUpBHfMmvJwdcJaoy3G4LUtY07iL7jJJTObCmCgG3V1VaAqngyQWaiV3Nk8GbSqW8akhMDMcXBPXHQJtoL/K5nKquDnF23H1xDL5UQo3wNW1BKo8hlRW86lfcaduCrTjspsL7GOwjnYqDZD98OSyVmfA34cUyk90jCsFP5qX/I7BNeOvAsTCQg+CpvHdxKsp1UjyeuNE+aP7kkeIbHjurOOPgjAOKMw7OOKA44+CMAwo9803BUk8O4tPfFFx6hJp1hq8c4lO6zmP9sq5HUoRuGeDSCN8O/5XA9PY001GmRm3lgIONLt0Fo48zXzcOmGWY1jdWlgB/4yv1qZXq0rp+Y7Ouq9enmBXd5np8ur6iKTSm+doZFjrXFmeg3lB/9Ux8cQn/AhOf3sSyLy00aszUorZxrK/3aSpfTdSXYKOxdcABHHLQqDaqG/HFhcbU8jLqyiE2G8srjy+3p4P45voSTK+ov/F1mFrZbGZTRK4AAAAhSURBVKzoV2BjaqWBrUK3Wb9Urdc0ybeRtjOv8gxfM/x/yPFMJoxcyNUAAAAASUVORK5CYII=\"\n",
    "display(Image(url=image_url, width=300))\n"
   ],
   "metadata": {
    "id": "lBHi7nea1Xkw",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:31.753041Z",
     "start_time": "2024-11-29T20:59:31.747736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "vector.ndim"
   ],
   "metadata": {
    "id": "Be-po73L2E8Y",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:32.924768Z",
     "start_time": "2024-11-29T20:59:32.921164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Matrix**"
   ],
   "metadata": {
    "id": "_5trphlF3Zq6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "matrix = torch.tensor([[7, 8],\n",
    "                       [9, 10]])\n",
    "matrix"
   ],
   "metadata": {
    "id": "CRqjCRhL3O2A",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:34.362044Z",
     "start_time": "2024-11-29T20:59:34.356694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "matrix.ndim\n"
   ],
   "metadata": {
    "id": "jy3a7JcH3j7-",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:34.941692Z",
     "start_time": "2024-11-29T20:59:34.939364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "matrix[0]"
   ],
   "metadata": {
    "id": "FGiNzyhs35NZ",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:36.367194Z",
     "start_time": "2024-11-29T20:59:36.364216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "matrix[1]"
   ],
   "metadata": {
    "id": "UbsKhlPW4adX",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:37.415184Z",
     "start_time": "2024-11-29T20:59:37.411617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "# Select the 8 in the first row\n",
    "matrix[0][1]"
   ],
   "metadata": {
    "id": "3APF4rkG4Cj9",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:38.202837Z",
     "start_time": "2024-11-29T20:59:38.199252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "matrix.shape"
   ],
   "metadata": {
    "id": "a5VZ3lws4Jr4",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:39.301083Z",
     "start_time": "2024-11-29T20:59:39.297799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "# Tensor\n",
    "tnsr = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "tnsr"
   ],
   "metadata": {
    "id": "b_oE7Ty04g7u",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:39.996467Z",
     "start_time": "2024-11-29T20:59:39.993309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "tnsr.ndim"
   ],
   "metadata": {
    "id": "McdZYwyX4lwT",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:40.704615Z",
     "start_time": "2024-11-29T20:59:40.701991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "*the tensor is 3-D*\n",
    "\n",
    "we can also notice that the number of preceeding and antecedant brackets=3 (That's how I remeber it b/c it gets confusing)"
   ],
   "metadata": {
    "id": "HSfIw-sP5wSk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tnsr.shape"
   ],
   "metadata": {
    "id": "5gXHEnO14sgI",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:42.151862Z",
     "start_time": "2024-11-29T20:59:42.149275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "**This is saying we have one 3x3 matrix**"
   ],
   "metadata": {
    "id": "A2YTDKD75LEZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "other_tnsr = torch.tensor([[[1, 2, 3]]])\n",
    "other_tnsr"
   ],
   "metadata": {
    "id": "VZT-8wXu462o",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:43.627882Z",
     "start_time": "2024-11-29T20:59:43.624211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "other_tnsr.shape"
   ],
   "metadata": {
    "id": "zXmEE9U35FLY",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:45.114017Z",
     "start_time": "2024-11-29T20:59:45.111261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Tensors\n",
    "\n",
    "Random tensors are important b/c many neural networks learn by starting with tensors full of random numbers and then adjust those random numbers as the data is being processed.\n",
    "\n",
    "The process is essentially this:\n",
    "\n",
    "`Start with random nums -> look at data -> update random nums -> look at data -> update random numbers -> rinse and repeat`\n",
    "\n",
    "*These numbers we're talking about are weights and biases and as processing goes along, those numbers get much less random*\n",
    "\n",
    "in the docs:\n",
    "https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html#random-tensors-and-seeding"
   ],
   "metadata": {
    "id": "bSESVBfP8UAK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Random Tensors\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ],
   "metadata": {
    "id": "sf1xzfWK5WT8",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:47.632278Z",
     "start_time": "2024-11-29T20:59:47.613671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6919, 0.4350, 0.7207, 0.1757],\n",
       "        [0.5414, 0.5618, 0.6002, 0.5656],\n",
       "        [0.1658, 0.9707, 0.2973, 0.4963]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "random_tensor.ndim"
   ],
   "metadata": {
    "id": "RGFN16uV-2Fw",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:48.722145Z",
     "start_time": "2024-11-29T20:59:48.719554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "another_rnd_tnsr = torch.rand(4,5)\n",
    "another_rnd_tnsr"
   ],
   "metadata": {
    "id": "PI_2or7k8Rgl",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:49.549034Z",
     "start_time": "2024-11-29T20:59:49.545405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2120, 0.2345, 0.6131, 0.1536, 0.0487],\n",
       "        [0.5050, 0.0850, 0.7310, 0.3876, 0.3385],\n",
       "        [0.9423, 0.8400, 0.4756, 0.8216, 0.3820],\n",
       "        [0.3245, 0.6862, 0.7731, 0.3143, 0.7605]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "another_rnd_tnsr.ndim"
   ],
   "metadata": {
    "id": "_7XHQUj_-vq9",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:50.956951Z",
     "start_time": "2024-11-29T20:59:50.954556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "yet_another_rnd_tnsr = torch.rand(3, 4, 5)\n",
    "yet_another_rnd_tnsr"
   ],
   "metadata": {
    "id": "D9-IFmpe-8p3",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:53.789384Z",
     "start_time": "2024-11-29T20:59:53.785710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6165, 0.6126, 0.5328, 0.6866, 0.2824],\n",
       "         [0.7691, 0.8622, 0.9961, 0.2622, 0.8505],\n",
       "         [0.0264, 0.5324, 0.4826, 0.0894, 0.6054],\n",
       "         [0.5855, 0.6932, 0.7033, 0.5175, 0.6063]],\n",
       "\n",
       "        [[0.7942, 0.0083, 0.9003, 0.8623, 0.6885],\n",
       "         [0.0288, 0.2319, 0.1181, 0.7179, 0.5081],\n",
       "         [0.5101, 0.1936, 0.4623, 0.9535, 0.4263],\n",
       "         [0.7762, 0.7571, 0.7469, 0.1111, 0.6392]],\n",
       "\n",
       "        [[0.9899, 0.3443, 0.9447, 0.1821, 0.0564],\n",
       "         [0.2422, 0.9762, 0.6097, 0.1381, 0.6358],\n",
       "         [0.4358, 0.9621, 0.4825, 0.6939, 0.9724],\n",
       "         [0.8032, 0.7786, 0.3167, 0.1255, 0.9057]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "yet_another_rnd_tnsr.ndim"
   ],
   "metadata": {
    "id": "YRbe-Y2Q_FQn",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:54.977490Z",
     "start_time": "2024-11-29T20:59:54.975269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # height, width, color channels (R,G,B)\n",
    "random_image_size_tensor"
   ],
   "metadata": {
    "id": "rEDFU8DZ_KVC",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:55.637158Z",
     "start_time": "2024-11-29T20:59:55.632026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8359, 0.5016, 0.3492],\n",
       "         [0.3330, 0.6550, 0.4688],\n",
       "         [0.6025, 0.8732, 0.3648],\n",
       "         ...,\n",
       "         [0.8090, 0.0802, 0.8271],\n",
       "         [0.9334, 0.3962, 0.7512],\n",
       "         [0.3897, 0.6298, 0.3198]],\n",
       "\n",
       "        [[0.9279, 0.8044, 0.0625],\n",
       "         [0.8779, 0.4920, 0.7024],\n",
       "         [0.1506, 0.9016, 0.0951],\n",
       "         ...,\n",
       "         [0.0470, 0.5213, 0.4401],\n",
       "         [0.0613, 0.8809, 0.9445],\n",
       "         [0.7502, 0.8124, 0.6537]],\n",
       "\n",
       "        [[0.2905, 0.9660, 0.0710],\n",
       "         [0.3401, 0.7271, 0.0188],\n",
       "         [0.7475, 0.4612, 0.6615],\n",
       "         ...,\n",
       "         [0.2828, 0.4001, 0.5365],\n",
       "         [0.4557, 0.6197, 0.4094],\n",
       "         [0.6973, 0.9119, 0.6916]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2437, 0.1600, 0.6540],\n",
       "         [0.5152, 0.1869, 0.1546],\n",
       "         [0.8592, 0.9185, 0.8702],\n",
       "         ...,\n",
       "         [0.5179, 0.8692, 0.4506],\n",
       "         [0.3961, 0.8053, 0.9100],\n",
       "         [0.7637, 0.0074, 0.1079]],\n",
       "\n",
       "        [[0.0949, 0.2150, 0.0769],\n",
       "         [0.6065, 0.2882, 0.1822],\n",
       "         [0.0426, 0.6662, 0.0280],\n",
       "         ...,\n",
       "         [0.5661, 0.7814, 0.5199],\n",
       "         [0.9636, 0.3545, 0.7285],\n",
       "         [0.0336, 0.1878, 0.3580]],\n",
       "\n",
       "        [[0.3471, 0.6005, 0.6085],\n",
       "         [0.2253, 0.4120, 0.8238],\n",
       "         [0.8785, 0.5541, 0.3816],\n",
       "         ...,\n",
       "         [0.6237, 0.6804, 0.5578],\n",
       "         [0.8649, 0.5938, 0.5813],\n",
       "         [0.9410, 0.4498, 0.0602]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": [
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ],
   "metadata": {
    "id": "B0BT5o46_5M-",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:57.331509Z",
     "start_time": "2024-11-29T20:59:57.328800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "second = torch.rand(size=(3, 3))\n",
    "second"
   ],
   "metadata": {
    "id": "1t2piWCXAAvR",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:57.807212Z",
     "start_time": "2024-11-29T20:59:57.803829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8471, 0.4309, 0.4317],\n",
       "        [0.6434, 0.3554, 0.9340],\n",
       "        [0.0543, 0.4581, 0.0744]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": [
    "second.shape, second.ndim"
   ],
   "metadata": {
    "id": "iOtS0xQ_BMkb",
    "ExecuteTime": {
     "end_time": "2024-11-29T20:59:58.294818Z",
     "start_time": "2024-11-29T20:59:58.292286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Manipulating Tensors\n",
    "\n",
    "**Tensor operations:**\n",
    "1. Addtion\n",
    "2. Subtraction\n",
    "3. Multiplication (element-wise)\n",
    "4. Division\n",
    "5. Matrix multiplication\n",
    "\n"
   ],
   "metadata": {
    "id": "nMkVZVHRmTXn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Addition"
   ],
   "metadata": {
    "id": "6MRRIn-cnZho"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.add(tensor, 10)"
   ],
   "metadata": {
    "id": "zEqoAKm7oKeq",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:00.121340Z",
     "start_time": "2024-11-29T20:59:59.952743Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m torch\u001B[38;5;241m.\u001B[39madd(tensor, \u001B[38;5;241m10\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ],
   "metadata": {
    "id": "0PA0_cHzBZ2B",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:00.344980Z",
     "start_time": "2024-11-29T21:00:00.341505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "Multiplication"
   ],
   "metadata": {
    "id": "HXz3rBjrni04"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.mul(tensor, 10)"
   ],
   "metadata": {
    "id": "TMnvCExBn-8k",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:00.863338Z",
     "start_time": "2024-11-29T21:00:00.859877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": [
    "tensor * 10"
   ],
   "metadata": {
    "id": "RvOEutkGnfCY",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:01.158504Z",
     "start_time": "2024-11-29T21:00:01.155641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "subtract"
   ],
   "metadata": {
    "id": "fvfi58Fhnwve"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tensor - 10"
   ],
   "metadata": {
    "id": "jU1R3yp1nnNR",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:01.685895Z",
     "start_time": "2024-11-29T21:00:01.681864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Matrix Multiplication\n",
    "\n",
    "Matrix multiplication is a binary operation that takes a pair of matrices and produces another matrix. Let's consider two matrices:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "a_{11} & a_{12} \\\\\n",
    "a_{21} & a_{22}\n",
    "\\end{bmatrix}\n",
    "\\quad \\text{and} \\quad\n",
    "B = \\begin{bmatrix}\n",
    "b_{11} & b_{12} \\\\\n",
    "b_{21} & b_{22}\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "### Dimensions Rule\n",
    "\n",
    "Matrix $A$ has dimensions $2 \\times 2$, and matrix $B$ also has dimensions $2 \\times 2$. For matrix multiplication, the number of columns in $A$ must equal the number of rows in $B$. The result will be a new matrix $C$ with dimensions $2 \\times 2$.\n",
    "\n",
    "### Element-wise Calculation\n",
    "\n",
    "The elements of the resulting matrix $C$ are calculated as follows:\n",
    "\n",
    "$$\n",
    "C = A \\cdot B = \\begin{bmatrix}\n",
    "c_{11} & c_{12} \\\\\n",
    "c_{21} & c_{22}\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $c_{11} = a_{11}b_{11} + a_{12}b_{21}$\n",
    "- $c_{12} = a_{11}b_{12} + a_{12}b_{22}$\n",
    "- $c_{21} = a_{21}b_{11} + a_{22}b_{21}$\n",
    "- $c_{22} = a_{21}b_{12} + a_{22}b_{22}$\n",
    "\n",
    "### Example\n",
    "\n",
    "Suppose:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\n",
    "\\quad \\text{and} \\quad\n",
    "B = \\begin{bmatrix}\n",
    "5 & 6 \\\\\n",
    "7 & 8\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "C = A \\cdot B = \\begin{bmatrix}\n",
    "1 \\cdot 5 + 2 \\cdot 7 & 1 \\cdot 6 + 2 \\cdot 8 \\\\\n",
    "3 \\cdot 5 + 4 \\cdot 7 & 3 \\cdot 6 + 4 \\cdot 8\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "19 & 22 \\\\\n",
    "43 & 50\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Matrix multiplication is a fundamental operation in linear algebra and forms the basis for many applications, including transformations in computer graphics, solving systems of linear equations, and machine learning algorithms.\n"
   ],
   "metadata": {
    "id": "0T9mDyCvpyad"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "R5lfEMKaqY_h"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Is Matrix Multiplication the Same as the Dot Product?\n",
    "\n",
    "Matrix multiplication and the dot product are related concepts in linear algebra, but they are **not the same thing**. Here's a breakdown of their differences and relationships:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Dot Product** (Scalar Product)\n",
    "- **Definition**: The dot product is an operation on two vectors that results in a **scalar** (a single number). It measures the magnitude of the projection of one vector onto another.\n",
    "  \n",
    "  For two vectors $\\mathbf{u}$ and $\\mathbf{v}$ in $\\mathbb{R}^n$:\n",
    "  $$\n",
    "  \\mathbf{u} \\cdot \\mathbf{v} = \\sum_{i=1}^n u_i v_i\n",
    "  $$\n",
    "\n",
    "  Example:\n",
    "  $$\n",
    "  \\mathbf{u} = [1, 2, 3], \\quad \\mathbf{v} = [4, 5, 6]\n",
    "  $$\n",
    "  $$\n",
    "  \\mathbf{u} \\cdot \\mathbf{v} = 1 \\cdot 4 + 2 \\cdot 5 + 3 \\cdot 6 = 32\n",
    "  $$\n",
    "\n",
    "- **Result**: A single scalar value.\n",
    "\n",
    "- **Dimensionality**: Both vectors must have the same number of elements.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Matrix Multiplication**\n",
    "- **Definition**: Matrix multiplication is a more general operation involving two matrices. It results in a **new matrix**. For matrix multiplication, the **number of columns in the first matrix must equal the number of rows in the second matrix**.\n",
    "\n",
    "  For matrices $A$ (of size $m \\times n$) and $B$ (of size $n \\times p$):\n",
    "  $$\n",
    "  C = A \\cdot B\n",
    "  $$\n",
    "  The element at position $c_{ij}$ in $C$ is computed as the **dot product** of the $i$-th row of $A$ and the $j$-th column of $B$:\n",
    "  $$\n",
    "  c_{ij} = \\sum_{k=1}^n a_{ik} b_{kj}\n",
    "  $$\n",
    "\n",
    "  Example:\n",
    "  $$\n",
    "  A = \\begin{bmatrix}\n",
    "  1 & 2 \\\\\n",
    "  3 & 4\n",
    "  \\end{bmatrix}, \\quad\n",
    "  B = \\begin{bmatrix}\n",
    "  5 & 6 \\\\\n",
    "  7 & 8\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "  $$\n",
    "  C = A \\cdot B = \\begin{bmatrix}\n",
    "  1 \\cdot 5 + 2 \\cdot 7 & 1 \\cdot 6 + 2 \\cdot 8 \\\\\n",
    "  3 \\cdot 5 + 4 \\cdot 7 & 3 \\cdot 6 + 4 \\cdot 8\n",
    "  \\end{bmatrix} = \\begin{bmatrix}\n",
    "  19 & 22 \\\\\n",
    "  43 & 50\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "\n",
    "- **Result**: A new matrix.\n",
    "\n",
    "- **Dimensionality**: The result has dimensions $m \\times p$, where $m$ is the number of rows in $A$ and $p$ is the number of columns in $B$.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Relationship Between Dot Product and Matrix Multiplication**\n",
    "- The **dot product** is a special case of matrix multiplication. Specifically:\n",
    "  - If $\\mathbf{u}$ and $\\mathbf{v}$ are vectors of size $1 \\times n$ and $n \\times 1$ respectively, then:\n",
    "    $$\n",
    "    \\mathbf{u} \\cdot \\mathbf{v} = \\begin{bmatrix} u_1 & u_2 & \\cdots & u_n \\end{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "    v_1 \\\\\n",
    "    v_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    v_n\n",
    "    \\end{bmatrix} = \\sum_{i=1}^n u_i v_i\n",
    "    $$\n",
    "    This produces a scalar, which is exactly the dot product.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "| Feature                  | Dot Product               | Matrix Multiplication       |\n",
    "|--------------------------|---------------------------|-----------------------------|\n",
    "| **Input**               | Two vectors               | Two matrices                |\n",
    "| **Output**              | Scalar                   | Matrix                     |\n",
    "| **Requirement**         | Same number of elements   | Columns of $A$ = Rows of $B$ |\n",
    "| **Special Case**         | No                       | Dot product is a special case |\n",
    "\n",
    "---\n",
    "\n",
    "In summary:\n",
    "- The **dot product** is a specific operation on vectors.\n",
    "- **Matrix multiplication** is a broader operation, and it uses the dot product to compute each element of the resulting matrix.\n"
   ],
   "metadata": {
    "id": "cn_fbxp1rmVl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Element wise multiplication"
   ],
   "metadata": {
    "id": "1bY6ITetuaQF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(tensor, \"*\", tensor)\n",
    "print(f'tensor * tensor = {tensor * tensor}')"
   ],
   "metadata": {
    "id": "p9BvGIZ8n1Q9",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:10.121151Z",
     "start_time": "2024-11-29T21:00:10.118451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "tensor * tensor = tensor([1, 4, 9])\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dot Product"
   ],
   "metadata": {
    "id": "sUCgZkt40a4J"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.matmul(tensor, tensor)"
   ],
   "metadata": {
    "id": "CERmiHZouKHs",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:11.716642Z",
     "start_time": "2024-11-29T21:00:11.712418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ],
   "metadata": {
    "id": "1kPk_lfn0ZRT",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:12.267254Z",
     "start_time": "2024-11-29T21:00:12.263497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: user 613 Âµs, sys: 1.05 ms, total: 1.66 ms\n",
      "Wall time: 1.66 ms\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ],
   "metadata": {
    "id": "4ydtMbe-0-_j",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:18.277867Z",
     "start_time": "2024-11-29T21:00:18.274027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 72 Âµs, sys: 39 Âµs, total: 111 Âµs\n",
      "Wall time: 109 Âµs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": [
    "*torch is fast*"
   ],
   "metadata": {
    "id": "iaDm5xTn1QSH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### One of the most common errors in Deep learning is shape errors\n",
    "\n",
    "*There are two main rulesd that performing matrix multiplication needs to satisfy:*\n",
    "1. The **inner dimensions** must match\n",
    "* (3, 2) @ (3, 2) WON'T WORK\n",
    "* (3, 2) @ (2, 3) WILL WORK\n",
    "2. The reulting matrix has the dimensions of the outer dimensions (3,2) @ (2, 3)--> 3, 3 matrix"
   ],
   "metadata": {
    "id": "XsKJE3I71vTQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.matmul(torch.rand(3, 2), torch.rand(3, 2))"
   ],
   "metadata": {
    "id": "otLX48Ku1D6w",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:22.628031Z",
     "start_time": "2024-11-29T21:00:22.594684Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[40], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m torch\u001B[38;5;241m.\u001B[39mmatmul(torch\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m2\u001B[39m), torch\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m2\u001B[39m))\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "source": [
    "torch.matmul(torch.rand(3, 2), torch.rand(2, 3))"
   ],
   "metadata": {
    "id": "zwPtMoB02tGN",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:23.257582Z",
     "start_time": "2024-11-29T21:00:23.253614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6542, 0.5699, 0.4522],\n",
       "        [0.5677, 0.5708, 0.2744],\n",
       "        [0.9273, 0.8638, 0.5543]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "source": [
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]])"
   ],
   "metadata": {
    "id": "5SkdTi982wDJ",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:25.221188Z",
     "start_time": "2024-11-29T21:00:25.219113Z"
    }
   },
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "source": [
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11],\n",
    "                         [9, 12]])"
   ],
   "metadata": {
    "id": "YvX05YQA4Dvt",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:25.865284Z",
     "start_time": "2024-11-29T21:00:25.862552Z"
    }
   },
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "source": [
    "torch.matmul(tensor_A, tensor_B) # could use torch.mm(Tensor_A, tensor_B)"
   ],
   "metadata": {
    "id": "-gHzJfZN4H4H",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:33.141210Z",
     "start_time": "2024-11-29T21:00:33.127273Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[44], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m torch\u001B[38;5;241m.\u001B[39mmatmul(tensor_A, tensor_B)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "source": [
    "tensor_A.shape, tensor_B.shape"
   ],
   "metadata": {
    "id": "kTwdjFFt4Puz",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:38.804113Z",
     "start_time": "2024-11-29T21:00:38.801462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": [
    "To fix tensor issues we can manpulate the shape of one of our tensors by using **Transpose**"
   ],
   "metadata": {
    "id": "seAkQTGY4oPp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tensor_B.T, tensor_B.T.shape"
   ],
   "metadata": {
    "id": "oBdxio_t4jJ7",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:41.956678Z",
     "start_time": "2024-11-29T21:00:41.950571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "source": [
    "torch.matmul(tensor_A, tensor_B.T)"
   ],
   "metadata": {
    "id": "9tQfpzJg5A1C",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:43.228175Z",
     "start_time": "2024-11-29T21:00:43.224921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'Tensor A shape: {tensor_A.shape}')\n",
    "print(f'Tensor B shape: {tensor_B.shape}')\n",
    "print(f'Tensor B Transpose shape: {tensor_B.T.shape}')\n",
    "print(f'Tensor A shape: {tensor_A.shape}')"
   ],
   "metadata": {
    "id": "35_PazlT5O0j",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:44.960108Z",
     "start_time": "2024-11-29T21:00:44.957597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A shape: torch.Size([3, 2])\n",
      "Tensor B shape: torch.Size([3, 2])\n",
      "Tensor B Transpose shape: torch.Size([2, 3])\n",
      "Tensor A shape: torch.Size([3, 2])\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'The output shape: {torch.matmul(tensor_A, tensor_B.T).shape}')"
   ],
   "metadata": {
    "id": "9OZ3YD8a5pby",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:46.522937Z",
     "start_time": "2024-11-29T21:00:46.520513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finding the min, max, mean, sum, etc (tensor aggregation)"
   ],
   "metadata": {
    "id": "mnAdwWFx62Qt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.arange(1, 101, 10)\n",
    "x"
   ],
   "metadata": {
    "id": "P5clr3Fm6oo3",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:50.049015Z",
     "start_time": "2024-11-29T21:00:50.044091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min()"
   ],
   "metadata": {
    "id": "JjMOdCKT7Msj",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:51.315316Z",
     "start_time": "2024-11-29T21:00:51.312028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(1))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "source": [
    "# Find the max\n",
    "torch.max(x), x.max()"
   ],
   "metadata": {
    "id": "rQmc7Db57a87",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:52.046326Z",
     "start_time": "2024-11-29T21:00:52.043317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(91), tensor(91))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "source": [
    "# NOTE: you need to define the dtype\n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ],
   "metadata": {
    "id": "nfYiamo57fdK",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:52.768332Z",
     "start_time": "2024-11-29T21:00:52.764309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(46.), tensor(46.))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "source": [
    "torch.sum(x), x.sum()"
   ],
   "metadata": {
    "id": "EstUTklB7utH",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:53.365752Z",
     "start_time": "2024-11-29T21:00:53.362576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(460), tensor(460))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "source": [
    "# index of min\n",
    "torch.argmin(x), x.argmin()"
   ],
   "metadata": {
    "id": "kpXBt4e08fX4",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:54.038514Z",
     "start_time": "2024-11-29T21:00:54.034558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "source": [
    "# index of max\n",
    "torch.argmax(x), x.argmax()"
   ],
   "metadata": {
    "id": "tCdr0FwT8sqj",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:55.086068Z",
     "start_time": "2024-11-29T21:00:55.081370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9), tensor(9))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "*Reshaping - reshapes an input tensor to a defined shape\n",
    "* View Return a view of an input tensor of a certain shape but keep the same memoery as the original tensor\n",
    "* Stacking - remove all `1` dimensions from tensor\n",
    "*from docs*\n",
    "torch.stack\n",
    "torch.stack(tensors, dim=0, *, out=None) â†’ Tensor\n",
    "Concatenates a sequence of tensors along a new dimension.\n",
    "\n",
    "**All tensors need to be of the same size.**\n",
    "`torch.squeeze` *from docs*\n",
    "`torch.squeeze`(input, dim=None) â†’ Tensor\n",
    "Returns a tensor with all specified dimensions of input of size 1 removed.\n",
    "\n",
    "* Unsqueez - adds a `1` dimension to a target tensor\n",
    "*from the docs*\n",
    "`torch.unsqueeze(input, dim)` â†’ Tensor\n",
    "Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "\n",
    "The returned tensor shares the same underlying data with this tensor.\n",
    "\n",
    "A dim value within the range $[-input.dim() - 1, input.dim() + 1)$ can be used. Negative dim will correspond to `unsqueeze()` applied at $dim = dim + input.dim() + 1.$\n",
    "\n",
    "* Permute - return a view of the input with dimansions permuted (swapped) in a certain way"
   ],
   "metadata": {
    "id": "tI9YWu6CC_dS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ],
   "metadata": {
    "id": "AsVazKDJ8vOy",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:57.044353Z",
     "start_time": "2024-11-29T21:00:57.040018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 9)\n",
    "x_reshaped, x_reshaped.shape"
   ],
   "metadata": {
    "id": "prWRptShEvGU",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:58.015210Z",
     "start_time": "2024-11-29T21:00:58.011682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "source": [
    "x_reshaped = x.reshape(9, 1)\n",
    "x_reshaped, x_reshaped.shape"
   ],
   "metadata": {
    "id": "HMfvNjjJE8km",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:00:59.065981Z",
     "start_time": "2024-11-29T21:00:59.062496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "source": [
    "# Change the view\n",
    "z = x.view(1, 9)\n",
    "z, z.shape"
   ],
   "metadata": {
    "id": "g0XkIk_oFXGq",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:00.238209Z",
     "start_time": "2024-11-29T21:01:00.234794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "source": [
    "# Changing z changes x (b/c a view of a tensor the same memory as the original)\n",
    "z[:,0] = 5\n",
    "z, x"
   ],
   "metadata": {
    "id": "3J2ARIGGFkbg",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:01.023560Z",
     "start_time": "2024-11-29T21:01:01.018329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "source": [
    "# Stack tensors on top of one another\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
    "x_stacked"
   ],
   "metadata": {
    "id": "kzdd8iU8GQ6b",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:01.852239Z",
     "start_time": "2024-11-29T21:01:01.848793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "source": [
    "x_stacked = torch.stack([x, x, x, x], dim=1)\n",
    "x_stacked"
   ],
   "metadata": {
    "id": "glQN1ZF7GgKU",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:02.897041Z",
     "start_time": "2024-11-29T21:01:02.893350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "source": [
    "squeeze"
   ],
   "metadata": {
    "id": "H9EF3VgaMDCi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# torch squeeze- removes all single diensions from a target tensor\n",
    "print(f'Previous tensor: {x_reshaped}')\n",
    "print(f'Previous shape: {x_reshaped.shape}')\n",
    "\n",
    "# Remove extra dimensions from x_reshaped"
   ],
   "metadata": {
    "id": "_7aL4XIcGvRP",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:04.378095Z",
     "start_time": "2024-11-29T21:01:04.374603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n",
      "Previous shape: torch.Size([9, 1])\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.zeros(2, 1, 2, 1, 2)\n",
    "print(x)\n",
    "print(x.size())\n",
    "y = torch.squeeze(x)\n",
    "print(f'torch.sqeeze(x) = {y.size()}')\n",
    "y = torch.squeeze(x, 0)\n",
    "print(f'torch.squeeze(x,0) = {y.size()}')\n",
    "y = torch.squeeze(x, 1)\n",
    "print(f'torch.squeexe(x,1) = {y.size()}')\n",
    "y = torch.squeeze(x, (1, 2, 3))\n",
    "print(f'torch.squeeze(x, (1,2,3) = {y.size()}')"
   ],
   "metadata": {
    "id": "CZi1sclIMppT",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:05.312006Z",
     "start_time": "2024-11-29T21:01:05.306601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0., 0.]],\n",
      "\n",
      "          [[0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0.]],\n",
      "\n",
      "          [[0., 0.]]]]])\n",
      "torch.Size([2, 1, 2, 1, 2])\n",
      "torch.sqeeze(x) = torch.Size([2, 2, 2])\n",
      "torch.squeeze(x,0) = torch.Size([2, 1, 2, 1, 2])\n",
      "torch.squeexe(x,1) = torch.Size([2, 2, 1, 2])\n",
      "torch.squeeze(x, (1,2,3) = torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "source": [
    "x_reshaped"
   ],
   "metadata": {
    "id": "Q6kjBt-tQWoJ",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:06.015705Z",
     "start_time": "2024-11-29T21:01:06.012600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [7.],\n",
       "        [8.],\n",
       "        [9.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "source": [
    "x_reshaped.shape"
   ],
   "metadata": {
    "id": "nFnfcZpNQkh5",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:06.759070Z",
     "start_time": "2024-11-29T21:01:06.756488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "source": [
    "x_reshaped.squeeze()\n"
   ],
   "metadata": {
    "id": "A7Dn1hGRQuVf",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:07.326071Z",
     "start_time": "2024-11-29T21:01:07.322090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "source": [
    "x_reshaped.squeeze().shape"
   ],
   "metadata": {
    "id": "C9ncgPwOQ1jv",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:07.956419Z",
     "start_time": "2024-11-29T21:01:07.953813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1, 2, 3, 4])\n",
    "unsqz0 = torch.unsqueeze(x, 0)\n",
    "print(unsqz0)\n",
    "unsqz1 = torch.unsqueeze(x, 1)\n",
    "print(unsqz1)"
   ],
   "metadata": {
    "id": "GObS2_neHX9X",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:08.701745Z",
     "start_time": "2024-11-29T21:01:08.698197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "source": [
    "# torch.permute\n",
    "x = torch.randn(2, 3, 5)\n",
    "print(x.size())\n",
    "print(x)"
   ],
   "metadata": {
    "id": "p-il_kxZLj9H",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:09.458806Z",
     "start_time": "2024-11-29T21:01:09.454840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "tensor([[[-0.2043,  0.5643, -0.1498,  1.3107,  0.9044],\n",
      "         [ 0.1200, -1.1549,  1.6540, -0.0677,  0.9804],\n",
      "         [-0.2896,  2.1615, -2.2304, -1.4529,  1.8639]],\n",
      "\n",
      "        [[-0.8329,  1.2506, -0.0868, -0.4159,  1.0055],\n",
      "         [ 2.1672, -0.3642, -0.7186, -0.9934, -1.5200],\n",
      "         [ 0.2194, -0.2257,  1.2537,  1.4308, -0.2590]]])\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "source": [
    "torch.permute(x, (2, 0, 1))"
   ],
   "metadata": {
    "id": "jBpTkRemVXCc",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:10.294537Z",
     "start_time": "2024-11-29T21:01:10.290371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2043,  0.1200, -0.2896],\n",
       "         [-0.8329,  2.1672,  0.2194]],\n",
       "\n",
       "        [[ 0.5643, -1.1549,  2.1615],\n",
       "         [ 1.2506, -0.3642, -0.2257]],\n",
       "\n",
       "        [[-0.1498,  1.6540, -2.2304],\n",
       "         [-0.0868, -0.7186,  1.2537]],\n",
       "\n",
       "        [[ 1.3107, -0.0677, -1.4529],\n",
       "         [-0.4159, -0.9934,  1.4308]],\n",
       "\n",
       "        [[ 0.9044,  0.9804,  1.8639],\n",
       "         [ 1.0055, -1.5200, -0.2590]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "source": [
    "torch.permute(x, (2, 0, 1)).size()"
   ],
   "metadata": {
    "id": "kW9GupsvViH6",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:10.954643Z",
     "start_time": "2024-11-29T21:01:10.951726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "source": [
    "x_original = torch.rand(size=(224, 224, 3)) # [height], [width], [color-channels]\n",
    "x_original.shape"
   ],
   "metadata": {
    "id": "Xv6JB1AzV4qC",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:11.484046Z",
     "start_time": "2024-11-29T21:01:11.481293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 3])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "source": [
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shift axis 0->1, 1->2, 2->0\n",
    "x_permuted.shape"
   ],
   "metadata": {
    "id": "nq9H_QgkW5Th",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:12.088754Z",
     "start_time": "2024-11-29T21:01:12.085827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Indexing\n",
    "\n",
    "Indexing with PyTorch is similar to NumPy"
   ],
   "metadata": {
    "id": "xKIJ1BUtYR7b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ],
   "metadata": {
    "id": "VNEMowYZXcA5",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:13.437822Z",
     "start_time": "2024-11-29T21:01:13.434750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "source": [
    "# let's index on our new tensor\n",
    "x[0]"
   ],
   "metadata": {
    "id": "8eqr_HnRYmcg",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:14.056682Z",
     "start_time": "2024-11-29T21:01:14.053723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "source": [
    "x[0][0]"
   ],
   "metadata": {
    "id": "9EhA9OTnY1Gy",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:14.684813Z",
     "start_time": "2024-11-29T21:01:14.681963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "source": [
    "x[0][0].shape"
   ],
   "metadata": {
    "id": "qKox18IaZyQO",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:15.274524Z",
     "start_time": "2024-11-29T21:01:15.271096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "source": [
    "x[0][1]"
   ],
   "metadata": {
    "id": "oYRnQnqcZA-k",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:15.857408Z",
     "start_time": "2024-11-29T21:01:15.853919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "source": [
    "x[0][2]"
   ],
   "metadata": {
    "id": "1yKjugObZIZm",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:16.456914Z",
     "start_time": "2024-11-29T21:01:16.454427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8, 9])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "source": [
    "# let's index on the most inner bracket\n",
    "x[0][0][0]"
   ],
   "metadata": {
    "id": "_RqZs7GSZNtU",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:16.969989Z",
     "start_time": "2024-11-29T21:01:16.967504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "source": [
    "x[0][0][1]"
   ],
   "metadata": {
    "id": "D9zN-YI0aTVl",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:17.564939Z",
     "start_time": "2024-11-29T21:01:17.561973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "source": [
    "x[0][1][1]"
   ],
   "metadata": {
    "id": "PcgWJKqRaYo8",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:18.047008Z",
     "start_time": "2024-11-29T21:01:18.044387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "source": [
    "# you can also use ':' to select 'all' of the target dimensions\n",
    "# here we are selecting all of the columns of the zeroth row\n",
    "x[:, 0]"
   ],
   "metadata": {
    "id": "BZnfqbU7ahxY",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:18.422584Z",
     "start_time": "2024-11-29T21:01:18.419876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "source": [
    "# get all of our values  og the 0th and 1st dimension but only index 1 of the second dimension\n",
    "x[:, :, 1]"
   ],
   "metadata": {
    "id": "aBcqCi1XbB7L",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:18.810234Z",
     "start_time": "2024-11-29T21:01:18.806752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "source": [
    "x[:, :, 2]"
   ],
   "metadata": {
    "id": "fbe1vPQOb1bT",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:20.437643Z",
     "start_time": "2024-11-29T21:01:20.434322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 9]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "source": [
    "# get all of the values of the 0 dimension but only 1 index value of the 1st and 2nd dimension\n",
    "x[:, 1, 1]"
   ],
   "metadata": {
    "id": "p92gQSHGcH75",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:21.063655Z",
     "start_time": "2024-11-29T21:01:21.061012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "source": [
    "# get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
    "x[0, 0, :]"
   ],
   "metadata": {
    "id": "VI7p-Wvkcw_4",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:22.118002Z",
     "start_time": "2024-11-29T21:01:22.115056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting Data from Tensors\n",
    "\n",
    "Like NumPy"
   ],
   "metadata": {
    "id": "cFPe9Xtb_9Td"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ],
   "metadata": {
    "id": "HNL3ZDpKd5dr",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:23.520587Z",
     "start_time": "2024-11-29T21:01:23.517537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's index on tensor\n",
    "x[0]"
   ],
   "metadata": {
    "id": "f3k1Vj0aAuAg",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:24.555598Z",
     "start_time": "2024-11-29T21:01:24.552237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "source": [
    "PyTorch Tensors and NumPy\n",
    "* data in NumPy array, want PyTorch Tensor ----> `torch.from_numpy(ndarray)`"
   ],
   "metadata": {
    "id": "SJrR48zjBXAs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# NumPy array to Tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array) # REMEMBER: PYTORCH DEFAULT IS FLOAT64\n",
    "array, tensor"
   ],
   "metadata": {
    "id": "ASz2sWWKA8Cw",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:26.253869Z",
     "start_time": "2024-11-29T21:01:26.248265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "source": [
    "array.dtype"
   ],
   "metadata": {
    "id": "qQ9BvH3EBSPa",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:27.088011Z",
     "start_time": "2024-11-29T21:01:27.085447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "source": [
    "torch.arange(1.0, 8.0).dtype\n"
   ],
   "metadata": {
    "id": "O5n82-QaB9f_",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:27.756100Z",
     "start_time": "2024-11-29T21:01:27.752674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "source": [
    "# Change the value of array, what will this do to tensor?\n",
    "array = array + 1\n",
    "array, tensor"
   ],
   "metadata": {
    "id": "pxZtm8RyCFbI",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:28.494470Z",
     "start_time": "2024-11-29T21:01:28.491411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "source": [
    "torch.arange(1.0, 8.0).dtype"
   ],
   "metadata": {
    "id": "qGlc6bidCv6Y",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:29.165620Z",
     "start_time": "2024-11-29T21:01:29.162990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "source": [
    "torch.arange(1, 8)"
   ],
   "metadata": {
    "id": "-mXKSRseC25i",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:29.688719Z",
     "start_time": "2024-11-29T21:01:29.685848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "source": [
    "# tensor to NumPy\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ],
   "metadata": {
    "id": "REDlLGlCC829",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:30.188626Z",
     "start_time": "2024-11-29T21:01:30.184858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "source": [
    "# Change the tensor, what happens to `numpy_tensor`\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ],
   "metadata": {
    "id": "HQ2y4gbGDgai",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:30.695958Z",
     "start_time": "2024-11-29T21:01:30.692725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reproducibility (trying to take the random out of random)\n",
    "\n",
    "`start with random numbers -> tensor operations -> update random numbers to try and make them a better representation of the data -> again -> again....etc..`\n",
    "\n",
    "To reduce the randomness in ther neural networks and PyTorch comes the concept of a **random seed**\n",
    "\n"
   ],
   "metadata": {
    "id": "yr87Ud-ZEzVA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.rand(3, 3)"
   ],
   "metadata": {
    "id": "HXZ6AbZKDwyi",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:33.032449Z",
     "start_time": "2024-11-29T21:01:33.029368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3592, 0.9898, 0.8144],\n",
       "        [0.9848, 0.0218, 0.6358],\n",
       "        [0.0549, 0.3636, 0.9601]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "source": [
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)"
   ],
   "metadata": {
    "id": "ebo97rQgFjMN",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:34.818945Z",
     "start_time": "2024-11-29T21:01:34.815676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.8414e-01, 8.3628e-01, 4.5460e-01, 2.0379e-01],\n",
      "        [1.9658e-04, 6.7769e-01, 7.4057e-01, 7.3460e-01],\n",
      "        [2.8849e-01, 8.5876e-02, 5.2751e-01, 7.7534e-01]])\n",
      "tensor([[0.8992, 0.3600, 0.6443, 0.3709],\n",
      "        [0.6782, 0.3615, 0.1834, 0.4846],\n",
      "        [0.5237, 0.1508, 0.4155, 0.9193]])\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "source": [
    "print(random_tensor_A == random_tensor_B)"
   ],
   "metadata": {
    "id": "Hebaji-PGYdj",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:36.001839Z",
     "start_time": "2024-11-29T21:01:35.999097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's make some random but reproducible tensors, notice we have to set the random seed twice\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "print(random_tensor_C)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)\n"
   ],
   "metadata": {
    "id": "a9yU9mNSGgXV",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:36.685486Z",
     "start_time": "2024-11-29T21:01:36.679714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Torch Reproducibility\n",
    "\n",
    "Completely reproducible results are not guaranteed across PyTorch releases, individual commits, or different platforms. Furthermore, results may not be reproducible between CPU and GPU executions, even when using identical seeds.\n",
    "\n",
    "However, there are some steps you can take to limit the number of sources of nondeterministic behavior for a specific platform, device, and PyTorch release. First, you can control sources of randomness that can cause multiple executions of your application to behave differently. Second, you can configure PyTorch to avoid using nondeterministic algorithms for some operations, so that multiple calls to those operations, given the same inputs, will produce the same result.\n",
    "\n",
    "** *Warning* **\n",
    "\n",
    "Deterministic operations are often slower than nondeterministic operations, so single-run performance may decrease for your model. However, determinism may save time in development by facilitating experimentation, debugging, and regression testing.\n",
    "\n",
    "Controlling sources of randomness\n",
    "PyTorch random number generator\n",
    "You can use `torch.manual_seed()` to seed the RNG for all devices (both CPU and CUDA):\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "ZY43CATWKv31"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# For custom operators, you might need to set python seed as well:\n",
    "import random\n",
    "random.seed(0)"
   ],
   "metadata": {
    "id": "rUiEudJPIJY3",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:40.986214Z",
     "start_time": "2024-11-29T21:01:40.984390Z"
    }
   },
   "outputs": [],
   "execution_count": 104
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random number generators in other libraries\n",
    "If you or any of the libraries you are using rely on NumPy, you can seed the global NumPy RNG with:\n",
    "\n"
   ],
   "metadata": {
    "id": "-HepexrhLwNU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)"
   ],
   "metadata": {
    "id": "OPNnrM-zLpsq",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:42.757680Z",
     "start_time": "2024-11-29T21:01:42.754351Z"
    }
   },
   "outputs": [],
   "execution_count": 105
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running tensors and PyTorch objects on GPU's (and making fater computations)\n",
    "\n",
    "GPU's = faster computation due to NVIDIA + CUDA + PyTorcvh working behind the scenes\n",
    "\n",
    "### Getting a GPU\n",
    "\n",
    "1. Easiest- Google Colab Pro\n",
    "2. Use Your Own - A few to choose from\n",
    "3. Cloud (AWS, Azure, Google Cloud)\n",
    "\n",
    "## For Mac:\n",
    "mps device enables high-performance training on GPU for MacOS devices with Metal programming framework. It introduces a new device to map Machine Learning computational graphs and primitives on highly efficient Metal Performance Shaders Graph framework and tuned kernels provided by Metal Performance Shaders framework respectively.\n",
    "\n",
    "The new MPS backend extends the PyTorch ecosystem and provides existing scripts capabilities to setup and run operations on GPU.\n",
    "\n",
    "To get started, simply move your Tensor and Module to the mps device:\n",
    "\n",
    "```\n",
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "    # Create a Tensor directly on the mps device\n",
    "    x = torch.ones(5, device=mps_device)\n",
    "    # Or\n",
    "    x = torch.ones(5, device=\"mps\")\n",
    "\n",
    "    # Any operation happens on the GPU\n",
    "    y = x * 2\n",
    "\n",
    "    # Move your model to mps just like any other device\n",
    "    model = YourFavoriteNet()\n",
    "    model.to(mps_device)\n",
    "\n",
    "    # Now every call runs on the GPU\n",
    "    pred = model(x)\n",
    "```\n",
    "\n",
    "reddit post for Mac M2pro\n",
    "\n",
    "https://www.reddit.com/r/pytorch/comments/13h46aj/pytorch_stuck_at_modeltomps_on_m2_pro/?rdt=46225\n",
    "\n",
    "\n",
    "### Also there is a course by Andrej Karpathy\n",
    "\n",
    "https://www.youtube.com/watch?v=q8SA3rM6ckI"
   ],
   "metadata": {
    "id": "t6_vyDW0MwOG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "math.log2(1/0.5)\n",
    "print(math.log2(1/0.5))"
   ],
   "metadata": {
    "id": "G6ULWSeqL1sK",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:01:52.193263Z",
     "start_time": "2024-11-29T21:01:52.191186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Let's test my Mac for the type of hardware accelerator \n",
    "**This Mac has an M2 pro chipset, here is a comparison as to how the M2pro chipset compares to GPU's used in PC's and Linux:**\n",
    "\n",
    "| **Feature**                | **M2 Pro (MPS)**                     | **Dedicated GPU (e.g., NVIDIA)**      |\n",
    "|----------------------------|-------------------------------------|---------------------------------------|\n",
    "| **Architecture**           | Integrated, unified memory         | Discrete, separate memory             |\n",
    "| **Performance**            | Suitable for many ML tasks         | Optimized for high-performance ML/AI |\n",
    "| **Software Support**       | Supported via MPS in PyTorch        | CUDA, cuDNN, TensorRT                 |\n",
    "| **Ease of Use**            | Simplified memory management       | Requires optimized code               |\n",
    "\n",
    "## Strengths and Weaknesses of the M2 Pro for ML\n",
    "**Strengths**\n",
    "* Portability: Ideal for on-the-go machine learning tasks.\n",
    "* Energy-efficient: Great for laptop users who need reasonable performance without draining the battery.\n",
    "* Unified memory: Simplifies handling of memory for smaller and medium-sized tasks.\n",
    "* Good PyTorch Support: MPS backend makes it relatively easy to use popular ML frameworks.\n",
    "Weaknesses\n",
    "* Limited memory for ML: Unified memory is shared with the CPU and other components, limiting the size of models and datasets you can handle.\n",
    "* Not optimized for large-scale workloads: Tasks like distributed training or working with massive datasets are not practical.\n",
    "* Less ecosystem support: Compared to CUDA-enabled GPUs, MPS has fewer optimizations and limited support in some libraries.\n",
    "\n",
    "# How Does It Compare to Other GPUs?\n",
    "\n",
    "\n",
    "### Performance Comparison\n",
    "\n",
    "| **Task**                       | **M2 Pro (MPS)**                           | **NVIDIA GPUs (e.g., RTX 3090, A100)**               |\n",
    "|--------------------------------|-------------------------------------------|-----------------------------------------------------|\n",
    "| **Model Training (Small Models)** | Competitive for smaller models like BERT-base | Significantly faster due to raw power and CUDA optimization |\n",
    "| **Model Training (Large Models)** | Slower, struggles with large datasets/models | Optimized for large models (e.g., GPT-3, BERT-large) |\n",
    "| **Inference**                  | Performs well on small-to-medium tasks     | Highly optimized for all inference workloads       |\n",
    "| **Batch Size**                 | Limited by unified memory architecture     | Handles larger batch sizes efficiently             |\n",
    "| **Energy Efficiency**          | Extremely energy-efficient                 | Higher power consumption                           |\n",
    "\n",
    "\n",
    "### Compatibility with ML Frameworks\n",
    "\n",
    "| **Framework/Library**            | **M2 Pro (MPS)**           | **NVIDIA GPUs (CUDA)**          |\n",
    "|----------------------------------|---------------------------|----------------------------------|\n",
    "| **PyTorch**                      | Supported via MPS          | Fully supported, optimized       |\n",
    "| **TensorFlow**                   | Basic support via CPU      | Fully supported with CUDA       |\n",
    "| **Hugging Face Transformers**    | Works well for BERT-based models | Fully supported with CUDA       |\n",
    "| **Specialized Libraries (e.g., RAPIDS)** | Not available               | Extensive ecosystem available   |\n",
    "\n",
    "### Key Use Cases\n",
    "\n",
    "| **Use Case**                     | **M2 Pro (MPS)**                     | **NVIDIA GPUs**                        |\n",
    "|----------------------------------|-------------------------------------|----------------------------------------|\n",
    "| **Fine-tuning Small Models**     | Performs well                       | Faster                                 |\n",
    "| **Training Large Models**        | Limited memory and compute           | Optimal for large-scale training       |\n",
    "| **Image Processing**             | Decent performance                  | Highly optimized                       |\n",
    "| **Natural Language Processing**  | Effective for BERT and similar models | Excellent, especially for larger models |\n",
    "| **Deep Learning Research**       | Limited for cutting-edge experiments | Fully equipped for cutting-edge ML     |\n",
    "\n",
    "### Comparison of GPUs\n",
    "\n",
    "| **GPU**          | **Raw Performance** | **Ease of Use**     | **Energy Efficiency** | **Best For**                               |\n",
    "|-------------------|---------------------|---------------------|------------------------|--------------------------------------------|\n",
    "| **M2 Pro (MPS)**  | Moderate            | High                | Excellent              | Portable ML tasks, fine-tuning small models|\n",
    "| **RTX 3090**      | High                | Moderate            | Moderate               | Heavy ML tasks, large models, research     |\n",
    "| **NVIDIA A100**   | Extremely High      | Moderate            | Low                    | Enterprise-scale ML, cutting-edge research |\n",
    "| **AMD GPUs**      | Moderate-High       | Low-Moderate         | Moderate               | Gaming and some ML workloads               |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())  # Should print True\n",
    "print(torch.device(\"mps\"))  # Confirms that MPS is the device\n"
   ],
   "metadata": {
    "id": "l1D97QNFafxt",
    "ExecuteTime": {
     "end_time": "2024-11-29T21:06:14.411370Z",
     "start_time": "2024-11-29T21:06:14.379556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "mps\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Another way to check for hardware acceleration on this MacbookPro**"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T21:40:59.219018Z",
     "start_time": "2024-11-29T21:40:59.214646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Check if MPS is available\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available: True\n",
      "PyTorch version: 2.2.2\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**MPS stands for Metal Performance Shaders**, a framework developed by Apple to provide high-performance, low-level access to GPU acceleration for machine learning and computational tasks. It is part of Appleâ€™s Metal framework, which is the foundation for graphics and compute processing on Apple devices.\n",
    "\n",
    "### What is Metal Performance Shaders?\n",
    "Metal Performance Shaders (MPS) is designed to:\n",
    "\n",
    "* Accelerate machine learning: MPS provides optimized GPU-accelerated math functions and pre-built neural network operations for deep learning tasks.\n",
    "* Simplify GPU usage: By abstracting complex GPU programming, MPS allows developers to focus on algorithms rather than GPU-specific details.\n",
    "* Leverage unified memory: On Apple Silicon (like M1 and M2), MPS takes advantage of the unified memory architecture, enabling efficient data sharing between the CPU and GPU.\n",
    "\n",
    "\n",
    "**Key Features of MPS**\n",
    "*Optimized Performance:*\n",
    "\n",
    "* Pre-built shaders for matrix multiplication, convolution, activation functions, and other deep learning primitives.\n",
    "* Tailored to Apple's GPU architecture for efficiency.\n",
    "\n",
    "**Ease of Integration:**\n",
    "\n",
    "* Integrated into popular frameworks like PyTorch and TensorFlow to provide seamless GPU acceleration on Apple Silicon.\n",
    "\n",
    "**Unified Memory Architecture:**\n",
    "\n",
    "* Removes the overhead of transferring data between the CPU and GPU.\n",
    "\n",
    "**Supports Metal Framework:**\n",
    "\n",
    "* Uses Appleâ€™s Metal API, which is the low-level graphics and compute API for macOS, iOS, and other Apple platforms.\n",
    "\n",
    "**Why is MPS Relevant?**\n",
    "* On Apple Silicon machines (like the M1, M2, and their Pro/Max/Ultra variants), MPS enables frameworks like PyTorch to utilize the GPU for computations, even though the hardware lacks support for CUDA, which is NVIDIA's GPU acceleration framework. MPS effectively acts as Appleâ€™s answer to CUDA.\n",
    "\n",
    "**How Does MPS Work with PyTorch?**\n",
    "* The MPS backend in PyTorch allows tensor operations and training workloads to run on Apple GPUs using Metal Performance Shaders. Itâ€™s particularly useful for:\n",
    "\n",
    "* Matrix operations (e.g., tensor multiplication).\n",
    "* Neural network layers (e.g., convolution, activation).\n",
    "* Accelerating machine learning tasks.\n",
    "\n",
    "TL;DR\n",
    "\n",
    "**MPS is a powerful framework that makes Apple's GPUs accessible for machine learning workloads. While not as widely adopted or as mature as NVIDIA's CUDA, it provides excellent performance for small to medium-sized ML tasks on Apple hardware, making the M2 Pro a capable device for deep learning projects.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| **Workload Level** | **Memory Usage (MB)** | **Memory Usage (GB)** | **Example Use Cases**                            |\n",
    "|---------------------|-----------------------|-----------------------|--------------------------------------------------|\n",
    "| **Low**            | < 500 MB             | < 0.5 GB             | Small datasets, fine-tuning small models (e.g., BERT-base), simple inference tasks. |\n",
    "| **Moderate**       | 500 MB â€“ 4 GB        | 0.5 GB â€“ 4 GB        | Medium datasets, training mid-sized models (e.g., ResNet-50, BERT-large), inference with larger models. |\n",
    "| **High**           | > 4 GB               | > 4 GB               | Large datasets, training large-scale models (e.g., GPT-3, Vision Transformers), distributed training. |\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T22:18:33.960060Z",
     "start_time": "2024-11-29T22:18:33.953177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup device agnostic code\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**so my hardware acceleration is available**"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Best practice: device agnostic code"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T22:20:20.286274Z",
     "start_time": "2024-11-29T22:20:20.283491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T22:20:44.158529Z",
     "start_time": "2024-11-29T22:20:41.756125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Define device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Example tensor\n",
    "x = torch.randn(3, 3).to(device)\n",
    "print(x)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "tensor([[ 2.2082, -0.6380,  0.4617],\n",
      "        [ 0.2674,  0.5349,  0.8094],\n",
      "        [ 1.1103, -1.6898, -0.9890]], device='mps:0')\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`tensor([...], device='mps:0')`\n",
    "\n",
    "* This specifies that the tensor is stored on the MPS device (mps:0).\n",
    "* In the MPS backend, thereâ€™s only one logical device (mps:0), as MPS does not support multi-GPU configurations like CUDA."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T22:34:52.338161Z",
     "start_time": "2024-11-29T22:34:52.332616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a tensor\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor on mps?\n",
    "print(tensor, tensor.device)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**move the tensor onto the Mac hardware accelerator**"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Of Note: if tensor is on device"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T22:37:26.448779Z",
     "start_time": "2024-11-29T22:37:26.444609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_on_mps = tensor.to(device)\n",
    "print(tensor_on_mps)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], device='mps:0')\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### How to Handle NumPy Arrays with MPS\n",
    "\n",
    "1. Convert the NumPy Array to a PyTorch Tensor Use torch.from_numpy() to convert the NumPy array to a PyTorch tensor.\n",
    "\n",
    "2. Move the Tensor to the MPS Device Use .to(\"mps\") to move the tensor to the MPS device.\n",
    "\n",
    "\n",
    "### Important Notes\n",
    "NumPy to PyTorch Conversion:\n",
    "\n",
    "The `torch.from_numpy()` function creates a PyTorch tensor that shares memory with the NumPy array. Changes to the original NumPy array will reflect in the PyTorch tensor and vice versa (on the CPU). Once moved to MPS, **they are no longer linked.**\n",
    "\n",
    "### MPS Compatibility:\n",
    "\n",
    "Not all data types are supported by the MPS backend. *Ensure your NumPy array contains a compatible data type, such as float32 or float64. PyTorch will handle the conversion automatically if needed.*\n",
    "\n",
    "#### Operations on MPS:\n",
    "\n",
    "Once on the MPS device, you can perform all PyTorch operations supported by the MPS backend.\n",
    "\n",
    "#### Limitations\n",
    "* NumPy operations themselves will still run on the CPU. You need to convert the array to a PyTorch tensor and use PyTorch for GPU-accelerated operations on MPS.\n",
    "* If you need to transfer results back to NumPy for further processing, use .cpu().numpy():\n",
    "`result_numpy = tensor_mps.cpu().numpy()`\n",
    "\n",
    "#### Summary\n",
    "While NumPy arrays cannot directly utilize MPS, you can:\n",
    "\n",
    "1. Convert the NumPy array to a PyTorch tensor.\n",
    "2. Move the tensor to the MPS device for GPU-accelerated computations.\n",
    "3. Convert it back to NumPy if needed after computation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T22:41:59.128897Z",
     "start_time": "2024-11-29T22:41:59.084357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Create a NumPy array\n",
    "numpy_array = np.random.rand(3, 3)\n",
    "\n",
    "# Convert NumPy array to a PyTorch tensor\n",
    "tensor = torch.from_numpy(numpy_array)\n",
    "\n",
    "# Move the tensor to MPS\n",
    "tensor_mps = tensor.to(\"mps\")\n",
    "\n",
    "print(f\"Original NumPy array:\\n{numpy_array}\")\n",
    "print(f\"PyTorch tensor on MPS:\\n{tensor_mps}\")\n"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[116], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(numpy_array)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Move the tensor to MPS\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m tensor_mps \u001B[38;5;241m=\u001B[39m tensor\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmps\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOriginal NumPy array:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnumpy_array\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPyTorch tensor on MPS:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mtensor_mps\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead."
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### There you see it won't work on mps\n",
    "##### To fix this type of problem"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T22:54:38.907988Z",
     "start_time": "2024-11-29T22:54:38.902603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_back_on_cpu = tensor_on_mps.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Now you are enlightened: Heavy Metal!**"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T22:56:34.999094Z",
     "start_time": "2024-11-29T22:56:34.990761Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_on_mps",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='mps:0')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
