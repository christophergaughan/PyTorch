{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMpN+FT+zNbNdGZRiCXXMVw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christophergaughan/PyTorch/blob/main/PyTorch_Custom_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here we must remember that there are 3 PyTorch Domains for using custom datasets. **Remember** Different domain Libraries contain DataLoading funtions for different data sources. i.e. you'll want to look into each of these PyTorch domain libraries for existing dqta loading functions and customizable data loading functions:\n",
        "\n",
        "* Visual- `torchvision.datasets`\n",
        "* Text - `torchtext.datasets`\n",
        "* Audio - `torchaudio.datasets`\n",
        "* Recommendation system - `torchrec.datasets`\n",
        "\n",
        "We've used some datasets with PyTorch so far.\n",
        "\n",
        "BUT, how do you get your own data into PyTorch?\n",
        "\n",
        "One way to do this is via *custom datasets*\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3obxn0MACeJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing PyTorch and setting up device agnostic code"
      ],
      "metadata": {
        "id": "h_5sY8yDHEzq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eyq6gxAPAuhJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "-C_YaBwDIaQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "3ri7eDa_IwIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data- we'll be getting food images (Food-101 Data Set)\n",
        "* we'll start off with just three categories of foodand use just 10% of the data\n",
        "* dataset is obviously just a subset of the full dataset.\n",
        "* 3 classes, 100 images/class\n",
        "* When starting out ML projects, it's important to try things on a small scale and only *then* increase the dataset i.e. scale it up\n",
        "* at this point speed of experients is is faster b/c datset is smaller"
      ],
      "metadata": {
        "id": "ZpRZLIABJriR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi data...\")\n",
        "        zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "JpSIT1Y2JWty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Becoming one with the data (data prep and data exploration)"
      ],
      "metadata": {
        "id": "HIkVbh6AO1UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "    \"\"\"\n",
        "    Walks through dir_path returning its contents.\n",
        "    Args:\n",
        "    dir_path (str or pathlib.Path): target directory\n",
        "    Return: target data directory\n",
        "    os.walk: directory tree maker\n",
        "    \"\"\"\n",
        "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'\")"
      ],
      "metadata": {
        "id": "KFJ2hYL2Mqjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "id": "PS7pesDWPrvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup our training and testing paths\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "nx3udGj5PtcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing an image\n",
        "\n",
        "let's write some code to:\n",
        "1. get all the image paths\n",
        "2. pick a random inage path using Pythons random choice()\n",
        "3. Get the image class name using `pathlib.Path.parent.stem`\n",
        "4. Since we're working with images, let's open the image with Python's PIL\n",
        "5. We'll show the image and print metadata"
      ],
      "metadata": {
        "id": "kk5EUaxeRFPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Set seed\n",
        "random.seed(42)\n",
        "\n",
        "# 1. Get all image paths (* means \"any combination\")\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "\n",
        "# 2. Get random image path\n",
        "random_image_path = random.choice(image_path_list)\n",
        "\n",
        "# 3. Get image class from path name (the image class is the name of the directory where the image is stored)\n",
        "image_class = random_image_path.parent.stem\n",
        "\n",
        "# 4. Open image\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "# 5. Print metadata\n",
        "print(f\"Random image path: {random_image_path}\")\n",
        "print(f\"Image class: {image_class}\")\n",
        "print(f\"Image height: {img.height}\")\n",
        "print(f\"Image width: {img.width}\")\n",
        "img"
      ],
      "metadata": {
        "id": "VVqeq472QKZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize with matplotlib"
      ],
      "metadata": {
        "id": "mMgmDGUnWIwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Turn the image into an array\n",
        "img_as_array = np.asarray(img)\n",
        "\n",
        "# Plot the image with matplotlib\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_as_array)\n",
        "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> (height, width, color_channels)\")\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "k5VbHSR-WH65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform all the images into torch.tensors\n",
        "\n",
        "before we can use our image data with PyTorch:\n",
        "1. Turn your target data into tensors\n",
        "2. Turn it into a `torch.utils.data.Dataset` and subsequently a `torch.utils.data.DataLoader`, we'll call those `dataset` and `DataLoader`\n",
        "\n",
        "NOTE:  we will be using `imagefolder` in PyTorch that has a `transform` function"
      ],
      "metadata": {
        "id": "_6hPgSmNYwN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "2bBN3FNVWH3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforming data with `torchvision.transforms`\n",
        "turn .jpeg's --> toch.tensors"
      ],
      "metadata": {
        "id": "7X6JJCueaeCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a transform for image\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize the images to 64x64\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    # Flip the images randomly on horizontal- data augmentation\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    # Turn the image into a torch.Tensor- normalizes from 0 --> 1\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "JmTio1mXWHzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform(img).shape"
      ],
      "metadata": {
        "id": "R8sjEf0VWCnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing transformed image\n",
        "transforms help you get your images ready to be used with model/perform *data augmentation*-\n",
        "https://pytorch.org/vision/stable/transforms.html"
      ],
      "metadata": {
        "id": "Sc3O3jaYdJyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_list[:5]"
      ],
      "metadata": {
        "id": "Nby6CsWIsvEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_transformed_images(image_paths: list, transform, n=3, seed=42):\n",
        "    \"\"\"Plots a series of random images from image_path_list.\n",
        "\n",
        "    Will open n image paths from image_paths, transform them\n",
        "    with transform and plot them side by side.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of target image paths.\n",
        "        transform (PyTorch Transforms): Transforms to apply to images.\n",
        "        n (int, optional): Number of images to plot. Defaults to 3.\n",
        "        seed (int, optional): Random seed for the random generator. Defaults to 42.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    random_image_paths = random.sample(image_paths, k=n)\n",
        "    for image_path in random_image_paths:\n",
        "        with Image.open(image_path) as f:\n",
        "            fig, ax = plt.subplots(nrows=1, ncols=2) # 1 row 2 cols\n",
        "            ax[0].imshow(f)\n",
        "            ax[0].set_title(f\"Original\\nSize: {f.size}\")\n",
        "            ax[0].axis(False)\n",
        "\n",
        "            # Transform and plot target image\n",
        "            # Note: permute() will change shape of image to suit matplotlib\n",
        "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
        "            transformed_image = transform(f).permute(1, 2, 0) # note we need to change the shape for matplotlib (C, H, W) -> (H, W, C)\n",
        "            ax[1].imshow(transformed_image)\n",
        "            ax[1].set_title(f\"Transformed\\nShape: {transformed_image.shape}\")\n",
        "            ax[1].axis(\"off\") # can use False\n",
        "\n",
        "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
        "\n",
        "plot_transformed_images(image_path_list,\n",
        "                        transform=data_transform,\n",
        "                        n=3)"
      ],
      "metadata": {
        "id": "9dRJwWxNTAib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note the original is better in quality than the transformed image\n",
        "there is less information encoded in the image. Thus, we may expect some loss\n",
        "in performance. However, this quality can be tunes as a **hyperparameter**.\n",
        "Note, that we are going with the `CNN explainer`, so this is where we are\n",
        "getting these image parameters from.\n",
        "\n",
        "**Note as well** that are images are flipped on the horizontal axis.\n",
        "\n",
        "**Note also** that our images are in `tensor format`. Thus these tensors are ready for implementing a model."
      ],
      "metadata": {
        "id": "68tKvNpay4nj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 1: Loading image dta using `ImageFolder`\n",
        "\n",
        "remeber that each one of the torchvision libraries have built-in functions to help you load data. here, using ImageFolder we note:\n",
        "\n",
        "```\n",
        "classtorchvision.datasets.ImageFolder(root: ~typing.Union[str, ~pathlib.Path], transform: ~typing.Optional[~typing.Callable] = None, target_transform: ~typing.Optional[~typing.Callable] = None, loader: ~typing.Callable[[str], ~typing.Any] = <function default_loader>, is_valid_file: ~typing.Optional[~typing.Callable[[str], bool]] = None, allow_empty: bool = False)\n",
        "```\n",
        "\n",
        "This library will help us load in images in the format we have specified. It is a pre-built `datsets` function. WE'RE LOADING IN OUR IMAGES AS TENSORS.\n",
        "\n",
        "* We can load image classification data using `torchvision.datasets.ImageFolder`\n",
        "* one of the advantges of using a PyTorch 'pre-built'\n",
        "\n",
        "https://pytorch.org/vision/0.20/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder"
      ],
      "metadata": {
        "id": "VIr203wY47eX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use ImageFolder to create dataset(s)\n",
        "from torchvision import datasets\n",
        "train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n",
        "                                  transform=data_transform, # transforms to perform on data (images) we write above\n",
        "                                  target_transform=None) # transforms to perform on labels/target (if necessary)\n",
        "\n",
        "test_data = datasets.ImageFolder(root=test_dir,\n",
        "                                 transform=data_transform)\n",
        "\n",
        "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
      ],
      "metadata": {
        "id": "e1G2yUiegtbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "r6Y_cQp_8eAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names as list\n",
        "class_names = train_data.classes # Changed 'trian_data' to 'train_data'\n",
        "class_names"
      ],
      "metadata": {
        "id": "rgmKaOQw81R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names as a dictionary- class names maped to dict\n",
        "class_dict = train_data.class_to_idx\n",
        "class_dict"
      ],
      "metadata": {
        "id": "IrPnfOtC9xnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cheeck the lengths of our datset\n",
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "YZTvfHb7-Tr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.samples[:10]"
      ],
      "metadata": {
        "id": "gUoBy76F-ua5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we have used `datsets.ImageFolder` to turn all our images into tensors and we did that with the help of `data.transform`, we've resized our images using `transform.Resize`, we've randomly flipped the data along the horizontal using `traansforms.RandomHorizontalFlip` (which we don't necessarily need but used to indicate what happens to an image when you passit through an image pipeline. Then most importantly we used `transform.ToTensor()` to allow our images to be *used with a PyTorch model*."
      ],
      "metadata": {
        "id": "hvXDXm2X_qBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Index on the the train_data Dataset to get a single image and label\n",
        "img, label = train_data[0][0], train_data[0][1]\n",
        "print(f\"Image tensor:\\n {img}\")\n",
        "print(f\"Image shape: {img.shape}\")\n",
        "print(f\"Image datatype: {img.dtype}\")\n",
        "print(f\"Image label: {label}\")\n",
        "print(f\"Label datatype: PyTorch: {type(label)}\")\n"
      ],
      "metadata": {
        "id": "8BsU8tRM_IV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This is like ana ccounting step where we see what forms our dataset is in to help with any errors we mifght account downstrem in our model"
      ],
      "metadata": {
        "id": "3LW_6ccCDuBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names[label]"
      ],
      "metadata": {
        "id": "Y9e77LG1CJnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**let's look at our data with matplotlib realizing where the color channel requirements are for matplotlib where it likew the color channels last (as they are different for PyTorch)**\n",
        "* we'll continue with our 'book-keeping' making sure datatypes match."
      ],
      "metadata": {
        "id": "MyPoofQrELQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rearrange the order dimensions\n",
        "img_permute = img.permute(1, 2, 0)\n",
        "\n",
        "# Print out different shapes\n",
        "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Image permuted {img_permute.shape} -> [height, width, color_channels]: \")\n",
        "# Rearrange the order dimensions\n",
        "img_permute = img.permute(1, 2, 0)\n",
        "\n",
        "# Print out different shapes\n",
        "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Image permuted -> [height, width, color_channels]: {img_permute.shape}\")\n",
        "\n",
        "# Plot the image\n",
        "plt.figure(figsize=(10, 7)) # Added parentheses here\n",
        "plt.imshow(img_permute)\n",
        "plt.axis(\"off\")\n",
        "plt.title(class_names[label], fontsize=14)"
      ],
      "metadata": {
        "id": "6VGVuEazCY-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch `DataLoader`- we've been working with these but a formal definition can only help: we turn our images datasets into `DataLoaders`\n",
        "\n",
        "## What is a `DataLoader`?\n",
        "The `DataLoader` in PyTorch is a utility that efficiently loads and iterates over datasets, particularly for deep learning tasks. It provides key functionalities such as:\n",
        "\n",
        "- **Batching**: Splits the dataset into mini-batches for more efficient training. Think of the situation where you had a large dataset and you had to load it all in at once. You run into *memory* problems. Even utilizing GPU's this would be the case. Thus we have the option of turning our images into batch sizes that is more easily digested by our system without overwhelming our memory constraints.\n",
        "- **Shuffling**: Randomly shuffles data at the start of each epoch to improve model generalization.\n",
        "- **Parallel Loading**: Uses multiple *num workers* to load data in parallel, improving performance.\n",
        "- **Automatic Batching**: Allows automatic collation of data samples into batches.\n",
        "- **Custom Sampling**: Supports custom samplers to define how data should be accessed.\n",
        "\n",
        "## Syntax/ hyperparameters\n",
        "```python\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    dataset,          # The dataset to load\n",
        "    batch_size=32,    # Number of samples per batch- this is variable depending on context\n",
        "    shuffle=True,     # Whether to shuffle data\n",
        "    num_workers=4     # e.g. Number of parallel workers (just know it is a possibility) for loading data. Think of a much larger dataset in the cloud\n",
        ")\n",
        "```\n",
        "# Why Do We Not Shuffle the Test Dataset in PyTorch?\n",
        "\n",
        "## Explanation\n",
        "When training a deep learning model, we typically set `shuffle=True` for the **training dataset** to improve generalization by preventing the model from learning the order of data. However, for the **test dataset**, we usually set `shuffle=False`. The reasons for this are:\n",
        "\n",
        "1. **Consistency in Evaluation**:  \n",
        "   - We want to evaluate the model on the same fixed order of test samples to ensure reproducibility.\n",
        "   \n",
        "2. **Sequential Dependencies**:  \n",
        "   - If the test data has a natural order (e.g., *time-series data*), shuffling it would disrupt the sequence, leading to incorrect evaluations.\n",
        "   \n",
        "3. **Batch-wise Predictions**:  \n",
        "   - In some applications, predictions need to be aligned with the original dataset order for post-processing.\n",
        "\n",
        "## Example: Loading Training and Test Datasets\n",
        "\n",
        "```python\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Custom dataset example- an OOP implementation is super-useful here\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.data = torch.arange(100)  # Example dataset with 100 samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "# Instantiate datasets\n",
        "train_dataset = CustomDataset()\n",
        "test_dataset = CustomDataset()\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)  # SShuffle for training\n",
        "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)   # No shuffle for testing\n",
        "\n",
        "# Iterating over train_loader (Shuffled)\n",
        "print(\"Training batches:\")\n",
        "for batch in train_loader:\n",
        "    print(batch)\n",
        "\n",
        "# Iterating over test_loader (Not shuffled)\n",
        "print(\"\\nTest batches:\")\n",
        "for batch in test_loader:\n",
        "    print(batch)\n",
        "\n"
      ],
      "metadata": {
        "id": "UdOU9ABhNish"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.cpu_count()"
      ],
      "metadata": {
        "id": "vCVExO8NU3Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn train and test datasets into DataLoader's\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE=1\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE, # how many samples per batch?\n",
        "                              num_workers=1, # how many subprocesses to work with- usually the more the better\n",
        "                              shuffle=True) # we don't want our model to memeorize data and thus diminish the generalizability of our model, shuffling the data reduces the chance that this happens\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             num_workers=1,\n",
        "                             shuffle=False) # if we want to look at our datset in the future, our test-data is always in the same order\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "jdQsgI5BJ2Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*so we have two instances of our dataloader*"
      ],
      "metadata": {
        "id": "C4QEdvFDV-NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataloader), len(test_dataloader)) # note output as we change BATCH_SIZE\n",
        "print(len(train_data), len(test_data))\n"
      ],
      "metadata": {
        "id": "AqmLvBImTFUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's interate through our train dataloader. This code snippet is designed to get a single batch of data (in this case, a single image and its corresponding label) from the `train_dataloader` and then print the shape of the image and the label."
      ],
      "metadata": {
        "id": "zVIw64nBY2Qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = next(iter(train_dataloader))\n",
        "\n",
        "# BATCH_SIZE  will now bw 1 you acn obviously change this parameter depending on the size of the model\n",
        "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
        "print(f\"Label shape: {label.shape} -> batch_size\")"
      ],
      "metadata": {
        "id": "NZSYt8OtTJJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What if we didn't have these conveient dataloader tools at our disposal? How would we load our data without them? Concurrently, what if we didn't have the ImageFolder class? How could we load our data-image set so that it's compatible with the DataLoader? Let's pretend we didn't have the TorchVision.datasets ImageFolder helper function. We could *still* replicate that functionality!\n",
        "* we want to get the class names as a list from our loaded data\n",
        "* we want to get our class names as a dictionary as well"
      ],
      "metadata": {
        "id": "QRh0FYOYe9aU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Image Data with a Custom `Dataset`\n",
        "\n",
        "Pro's:\n",
        "* Can create a `DataSet` out of almost anything\n",
        "* Not limited to PyTorch pre-built `Dataset` functions\n",
        "\n",
        "Cons\n",
        "* Even though you could create `Dataset` out of almost anything, it doesn't mean it will work\n",
        "* Using a custom `Dataset` often results in us writing more code, which could be prone to errors and/or performance issues"
      ],
      "metadata": {
        "id": "6rVHIE1FAj_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from typing import Tuple, Dict, List"
      ],
      "metadata": {
        "id": "GT59_na9aI_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instance of torchvision.datasets.ImageFolder()\n",
        "train_data.classes, train_data.class_to_idx"
      ],
      "metadata": {
        "id": "QsDwE9H6DG0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will map our imge names to their class by passing a file path to a function."
      ],
      "metadata": {
        "id": "sL7pwWlidVUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a helper function to get class names\n",
        "\n",
        "We want to:\n",
        "1. Get claass names using `os.scandir()` to traverse a target directory (ideally the directory is in standard image classification format).\n",
        "2. Raise an error if the class names aren't found (if this happens, there might be something wrong with the directory structure).\n",
        "3. Turn the class names into dict and a list- return them"
      ],
      "metadata": {
        "id": "zRRQtBRPd5J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up ath for target directory\n",
        "target_directory = train_dir\n",
        "print(f\"Target dir: {target_directory}\")\n",
        "\n",
        "# Get the class names from the target directory\n",
        "class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory))])\n",
        "class_names_found\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "FJBZEAcAESFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(os.scandir(target_directory))"
      ],
      "metadata": {
        "id": "cDRL_5w4iglf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
        "    \"\"\"Finds the class folder names in a target directory.\n",
        "\n",
        "    Assumes the target directory is in standard image classification format.\n",
        "\n",
        "    Args:\n",
        "        directory (str): Target directory to scan.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str\n",
        "    \"\"\"\n",
        "    # 1. Get the class names by scanning the target directory\n",
        "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
        "\n",
        "\n",
        "    # 2. Raise an error if class names not found\n",
        "    if not classes:\n",
        "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
        "\n",
        "    # 3 Create a dictionary of index labels (computers prefer numbers rather than strings as labels)\n",
        "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
        "\n",
        "    return classes, class_to_idx"
      ],
      "metadata": {
        "id": "IpT3vkGOjQnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_classes(train_dir)"
      ],
      "metadata": {
        "id": "gmFmuG5nmw4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a custom `Dataset` to replicate `ImageFolder`\n",
        "\n",
        "To craete our own custom dataset, we want to:\n",
        "1. Subclass `torch.utils.data.Dataset`\n",
        "2. Init our subclass with a target directoryc (the directory we'd like to get data from) as well as a transform if we'd like to trasform the data.\n",
        "3. Create several attributes:\n",
        "    * paths - paths of our images\n",
        "    * transform - the trasform we'd like to use\n",
        "    * classes - a list of the target classes\n",
        "    * class_to_idx - dict of the target classes mapped to integer labels\n",
        "4. Ceate a function to `load images()`, this function will open an image\n",
        "5. Overwrite `__len()__` method to return the length of the dataset\n",
        "6. Overwrite `__getitem()__` method to returm a given sample when passed an index"
      ],
      "metadata": {
        "id": "cQU5bCSApgsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a custom dataset class (inherits from torch.utils.data.Dataset)\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# 1. Subclass torch.utils.data.Dataset\n",
        "class ImageFolderCustom(Dataset):\n",
        "\n",
        "    # 2. Initialize with a targ_dir and transform (optional) parameter\n",
        "    def __init__(self, targ_dir: str, transform=None) -> None:\n",
        "\n",
        "        # 3. Create class attributes\n",
        "        # Get all image paths\n",
        "        self.paths = list(pathlib.Path(targ_dir).glob(\"*/*.jpg\")) # note: you'd have to update this if you've got .png's or .jpeg's\n",
        "        # Setup transforms\n",
        "        self.transform = transform\n",
        "        # Create classes and class_to_idx attributes\n",
        "        self.classes, self.class_to_idx = find_classes(targ_dir)\n",
        "\n",
        "    # 4. Make function to load images\n",
        "    def load_image(self, index: int) -> Image.Image:\n",
        "        \"Opens an image via a path and returns it.\"\n",
        "        image_path = self.paths[index]\n",
        "        return Image.open(image_path)\n",
        "\n",
        "    # 5. Overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)\n",
        "    def __len__(self) -> int:\n",
        "        \"Returns the total number of samples.\"\n",
        "        return len(self.paths)\n",
        "\n",
        "    # 6. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)\n",
        "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
        "        \"Returns one sample of data, data and label (X, y).\"\n",
        "        img = self.load_image(index)\n",
        "        class_name  = self.paths[index].parent.name # expects path in data_folder/class_name/image.jpeg\n",
        "        class_idx = self.class_to_idx[class_name]\n",
        "\n",
        "        # Transform if necessary\n",
        "        if self.transform:\n",
        "            return self.transform(img), class_idx # return data, label (X, y)\n",
        "        else:\n",
        "            return img, class_idx # return data, label (X, y)"
      ],
      "metadata": {
        "id": "lT3IavPRm7iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a transform\n",
        "from torchvision import transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Don't augment test data, only reshape\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "CgG4BYMMxNZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom = ImageFolderCustom(targ_dir=train_dir,\n",
        "                                      transform=train_transforms)\n",
        "test_data_custom = ImageFolderCustom(targ_dir=test_dir,\n",
        "                                     transform=test_transforms)\n",
        "train_data_custom, test_data_custom\n"
      ],
      "metadata": {
        "id": "FO5qYzF4yVB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data_custom), len(test_data_custom)"
      ],
      "metadata": {
        "id": "33gJroBAy903"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom.classes"
      ],
      "metadata": {
        "id": "QVwTo8o0Ju2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "q-NVOemwzAE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data_custom), len(test_data_custom), len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "yYArHEBFzJFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom.classes, train_data_custom.class_to_idx"
      ],
      "metadata": {
        "id": "HZ5bBhBp3kvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for equality amongst our custom Dataset and ImageFolder Dataset\n",
        "print((len(train_data_custom) == len(train_data)) & (len(test_data_custom) == len(test_data)))\n",
        "print(train_data_custom.classes == train_data.classes)\n",
        "print(train_data_custom.class_to_idx == train_data.class_to_idx)"
      ],
      "metadata": {
        "id": "1rFKLumx4DlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a function to display random images\n",
        "\n",
        "1. Take a `Dataset` and a number of other parameters such as class names and how many images to visualize\n",
        "2. To prevent the display getting out of hand, let cap the number of images to 10.\n",
        "3. Set random seed for reproducibility\n",
        "4. Get a list of random indices from the target dataset\n",
        "5. Set up a matplotlib plot\n",
        "6 Make sure the dimensions of our images line up with Matplotlib(HWC) as opposed to PyTorch(CHW)"
      ],
      "metadata": {
        "id": "2W6WvzEe-kwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Take in a Dataset as well as a list of class names\n",
        "def display_random_images(dataset: torch.utils.data.dataset.Dataset,\n",
        "                          classes: List[str] = None,\n",
        "                          n: int = 10,\n",
        "                          display_shape: bool = True,\n",
        "                          seed: int = None):\n",
        "\n",
        "    # 2. Adjust display if n too high\n",
        "    if n > 10:\n",
        "        n = 10\n",
        "        display_shape = False\n",
        "        print(f\"For display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display.\")\n",
        "\n",
        "    # 3. Set random seed\n",
        "    if seed:\n",
        "        random.seed(seed)\n",
        "\n",
        "    # 4. Get random sample indexes\n",
        "    random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
        "\n",
        "    # 5. Setup plot\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    # 6. Loop through samples and display random samples\n",
        "    for i, targ_sample in enumerate(random_samples_idx):\n",
        "        targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
        "\n",
        "        # 7. Adjust image tensor shape for plotting: [color_channels, height, width] -> [color_channels, height, width]\n",
        "        targ_image_adjust = targ_image.permute(1, 2, 0)\n",
        "\n",
        "        # Plot adjusted samples\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(targ_image_adjust)\n",
        "        plt.axis(\"off\")\n",
        "        if classes:\n",
        "            title = f\"class: {classes[targ_label]}\"\n",
        "            if display_shape:\n",
        "                title = title + f\"\\nshape: {targ_image_adjust.shape}\"\n",
        "        plt.title(title)\n"
      ],
      "metadata": {
        "id": "n7auLvCZ-MZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display random images from ImageFolder created Dataset\n",
        "display_random_images(train_data,\n",
        "                      n=5,\n",
        "                      classes=class_names,\n",
        "                      seed=42)"
      ],
      "metadata": {
        "id": "1-nKutLhF_Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now with the Dataset we created with our own ImageFolderCustom.\n",
        "\n"
      ],
      "metadata": {
        "id": "cQbbgF1MKRqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display random images from ImageFolderCustom Dataset\n",
        "display_random_images(train_data_custom,\n",
        "                      n=5,\n",
        "                      classes=class_names,\n",
        "                      seed=42) # Try setting the seed for reproducible images"
      ],
      "metadata": {
        "id": "qGoUD9KqGrKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turn our custom loaded images into a DataLoader"
      ],
      "metadata": {
        "id": "CmNtk5xTLiPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "train_dataloader_custom = DataLoader(dataset=train_data_custom,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     num_workers=NUM_WORKERS,\n",
        "                                     shuffle=True)\n",
        "\n",
        "test_dataloader_custom = DataLoader(dataset=test_data_custom,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    num_workers=NUM_WORKERS,\n",
        "                                    shuffle=False)\n",
        "\n",
        "train_dataloader_custom, test_dataloader_custom"
      ],
      "metadata": {
        "id": "b-I0iwhvKVep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get image and label from custom dataloader\n",
        "img_custom, label_custom = next(iter(train_dataloader_custom))\n",
        "\n",
        "# Print out shapes\n",
        "img_custom.shape, label_custom.shape"
      ],
      "metadata": {
        "id": "mWxSruDQNkfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LTBverUZOJ3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ctcjXIzcOvFR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}