{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNATPdG912QfA/n9HZb5VRM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christophergaughan/PyTorch/blob/main/PyTorch_Custom_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here we must remember that there are 3 PyTorch Domains for using custom datasets. **Remeber** Different domain Libraries contain DataLoading funtions for different data sources. i.e. you'll want to look into each of these PyTorch domain libraries for existing dqta loading functions and customizable data loading functions:\n",
        "\n",
        "* Visual- `torchvision.datasets`\n",
        "* Text - `torchtext.datasets`\n",
        "* Audio - `torchaudio.datasets`\n",
        "* Recommendation system - `torchrec.datasets`\n",
        "\n",
        "We've used some datasets with PyTorch so far.\n",
        "\n",
        "BUT, how do you get your own data into PyTorch?\n",
        "\n",
        "One way to do this is via *custom datasets*\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3obxn0MACeJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing PyTorch and setting up device agnostic code"
      ],
      "metadata": {
        "id": "h_5sY8yDHEzq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eyq6gxAPAuhJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "-C_YaBwDIaQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "3ri7eDa_IwIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data- we'll be getting food images (Food-101 Data Set)\n",
        "* we'll start off with just three categories of foodand use just 10% of the data\n",
        "* dataset is obviously just a subset of the full dataset.\n",
        "* 3 classes, 100 images/class\n",
        "* When starting out ML projects, it's important to try things on a small scale and only *then* increase the dataset i.e. scale it up\n",
        "* at this point speed of experients is is faster b/c datset is smaller"
      ],
      "metadata": {
        "id": "ZpRZLIABJriR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi data...\")\n",
        "        zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "JpSIT1Y2JWty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Becoming one with the data (data prep and data exploration)"
      ],
      "metadata": {
        "id": "HIkVbh6AO1UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "    \"\"\"\n",
        "    Walks through dir_path returning its contents.\n",
        "    Args:\n",
        "    dir_path (str or pathlib.Path): target directory\n",
        "    Return: target data directory\n",
        "    os.walk: directory tree maker\n",
        "    \"\"\"\n",
        "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'\")"
      ],
      "metadata": {
        "id": "KFJ2hYL2Mqjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "id": "PS7pesDWPrvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup our training and testing paths\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "nx3udGj5PtcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing an image\n",
        "\n",
        "let's write some code to:\n",
        "1. get all the image paths\n",
        "2. pick a random inage path using Pythons random choice()\n",
        "3. Get the image class name using `pathlib.Path.parent.stem`\n",
        "4. Since we're working with images, let's open the image with Python's PIL\n",
        "5. We'll show the image and print metadata"
      ],
      "metadata": {
        "id": "kk5EUaxeRFPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import random\n",
        "from PIL import Image\n",
        "\n",
        "# Set seed\n",
        "random.seed(42) # <- try changing this and see what happens\n",
        "\n",
        "# 1. Get all image paths (* means \"any combination\")\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "\n",
        "# 2. Get random image path\n",
        "random_image_path = random.choice(image_path_list)\n",
        "\n",
        "# 3. Get image class from path name (the image class is the name of the directory where the image is stored)\n",
        "image_class = random_image_path.parent.stem\n",
        "\n",
        "# 4. Open image\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "# 5. Print metadata\n",
        "print(f\"Random image path: {random_image_path}\")\n",
        "print(f\"Image class: {image_class}\")\n",
        "print(f\"Image height: {img.height}\")\n",
        "print(f\"Image width: {img.width}\")\n",
        "img"
      ],
      "metadata": {
        "id": "VVqeq472QKZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### That doesn't look like 'Pizza'"
      ],
      "metadata": {
        "id": "qx7N-HVuVyLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize with matplotlib"
      ],
      "metadata": {
        "id": "mMgmDGUnWIwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Turn the image into an array\n",
        "img_as_array = np.asarray(img)\n",
        "\n",
        "# Plot the image with matplotlib\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_as_array)\n",
        "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> (height, width, color_channels)\")\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "k5VbHSR-WH65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform all the images into torch.tensors\n",
        "\n",
        "before we can use our image data with PyTorch:\n",
        "1. Turn your target data into tensors\n",
        "2. Turn it into a `torch.utils.data.Dataset` and subsequently a `torch.utils.data.DataLoader`, we'll call those `dataset` and `DataLoader`\n",
        "\n",
        "NOTE:  we will be using `imagefolder` in PyTorch that has a `transform` function"
      ],
      "metadata": {
        "id": "_6hPgSmNYwN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "2bBN3FNVWH3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforming data with `torchvision.transforms`\n",
        "turn .jpeg's --> toch.tensors"
      ],
      "metadata": {
        "id": "7X6JJCueaeCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a transform for image\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize the images to 64x64\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    # Flip the images randomly on horizontal- data augmentation\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    # Turn the image into a torch.Tensor- normalizes from 0 --> 1\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "JmTio1mXWHzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform(img).shape"
      ],
      "metadata": {
        "id": "R8sjEf0VWCnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing transformed image\n",
        "transforms help you get your images ready to be used with model/perform data augmentation-\n",
        "https://pytorch.org/vision/stable/transforms.html"
      ],
      "metadata": {
        "id": "Sc3O3jaYdJyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_transformed_images(image_paths, transform, n=3, seed=42):\n",
        "    \"\"\"Plots a series of random images from image_paths.\n",
        "\n",
        "    Will open n image paths from image_paths, transform them\n",
        "    with transform and plot them side by side.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of target image paths.\n",
        "        transform (PyTorch Transforms): Transforms to apply to images.\n",
        "        n (int, optional): Number of images to plot. Defaults to 3.\n",
        "        seed (int, optional): Random seed for the random generator. Defaults to 42.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    random_image_paths = random.sample(image_paths, k=n)\n",
        "    for image_path in random_image_paths:\n",
        "        with Image.open(image_path) as f:\n",
        "            fig, ax = plt.subplots(1, 2)\n",
        "            ax[0].imshow(f)\n",
        "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
        "            ax[0].axis(\"off\")\n",
        "\n",
        "            # Transform and plot image\n",
        "            # Note: permute() will change shape of image to suit matplotlib\n",
        "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
        "            transformed_image = transform(f).permute(1, 2, 0) # note we need to change the shape for matplotlib (C, H, W) -> (H, W, C)\n",
        "            ax[1].imshow(transformed_image)\n",
        "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
        "            ax[1].axis(\"off\")\n",
        "\n",
        "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
        "\n",
        "plot_transformed_images(image_path_list,\n",
        "                        transform=data_transform,\n",
        "                        n=3)"
      ],
      "metadata": {
        "id": "9dRJwWxNTAib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1G2yUiegtbJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}