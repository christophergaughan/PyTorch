{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM8x6VQMV5lwCy6tGBOsBqJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christophergaughan/PyTorch/blob/main/Copy_of_ComputerVision_Excercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I will ise the CIFAR-10 dataset for this notebook:\n",
        "* CIFAR-10: 60,000 32x32 color images in 10 classes (e.g., airplane, dog, car, bird).\n",
        "* instead of the color channel being 1 (Greyscale images they will be in color)\n",
        "* has 60,000 32x32 color images with 10 classes\n",
        "* Tensor Shape:\n",
        "[batch_size, color_channels, height, width]\n",
        "\n",
        "For the example with CIFAR-10:\n",
        "\n",
        "* `batch_size`: Number of images in each batch (e.g., 32).\n",
        "* `color_channels`: Number of channels in the image. Since CIFAR-10 uses RGB * `images`, this would be 3.\n",
        "`height and width`: The dimensions of the image. CIFAR-10 images are 32x32.\n",
        "So, your input tensor will indeed have the shape [32, 3, 32, 32] if you are processing 32 images per batch."
      ],
      "metadata": {
        "id": "Ge7WOsTsfebz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP5UfxewexO9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cS4NRGvXfUOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To incorporate normalization into your CIFAR-10 dataset preparation while still keeping the structure clean and readable, here's how the code should be written:"
      ],
      "metadata": {
        "id": "Cant5V1GxTB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define transforms with normalization\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to tensor format\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize RGB channels to [-1, 1]\n",
        "])\n",
        "\n",
        "# Setup Training data\n",
        "train_data = datasets.CIFAR10(\n",
        "    root=\"data\",          # where to download data to\n",
        "    train=True,           # do we want the training dataset?\n",
        "    download=True,        # do we want to download?\n",
        "    transform=data_transforms  # Apply defined transformations\n",
        ")\n",
        "\n",
        "# Setup Testing data\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=data_transforms  # Apply the same transformations as training\n",
        ")\n",
        "\n",
        "# Create DataLoaders for batching\n",
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True  # Shuffle the data for training\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False  # No need to shuffle test data\n",
        ")\n",
        "\n",
        "# Check data shapes\n",
        "print(f\"Number of training samples: {len(train_data)}\")\n",
        "print(f\"Number of testing samples: {len(test_data)}\")\n",
        "\n",
        "# Example: Iterate through the train_loader\n",
        "for images, labels in train_loader:\n",
        "    print(f\"Batch image shape: {images.shape}\")  # Should be [batch_size, 3, 32, 32]\n",
        "    print(f\"Batch label shape: {labels.shape}\")  # Should be [batch_size]\n",
        "    break\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RHElLWNrXinD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See the first training data- this will output the data as tensors (C x H x W) NOTE: RGB scale images only have 3 color channels\n",
        "image, label = train_data[0]\n",
        "image, label"
      ],
      "metadata": {
        "id": "2CuP01XMkwGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ],
      "metadata": {
        "id": "cx9Zi3zpzEim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets[:5]"
      ],
      "metadata": {
        "id": "CcF2YYk715Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# CIFAR-10 class names\n",
        "class_names = train_data.classes\n",
        "\n",
        "# Get an image and label from the dataset\n",
        "image, label = train_data[0]\n",
        "print(f\"Image Shape: {image.shape}\")  # Should be [3, 32, 32]\n",
        "\n",
        "# Reverse the normalization (if applied)\n",
        "# (image * std + mean) for each channel to bring values back to [0, 1]\n",
        "mean = np.array([0.5, 0.5, 0.5])\n",
        "std = np.array([0.5, 0.5, 0.5])\n",
        "image = image.permute(1, 2, 0).numpy()  # Convert to [H, W, C]\n",
        "image = (image * std) + mean  # Reverse normalization\n",
        "image = np.clip(image, 0, 1)  # Ensure values are in [0, 1]\n",
        "\n",
        "# Plot the image\n",
        "plt.imshow(image)\n",
        "plt.title(class_names[label])\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oX2LN_Ly2aRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot multiple images from the dataset\n",
        "torch.manual_seed(42)  # For reproducibility\n",
        "fig = plt.figure(figsize=(9, 9))  # Create a figure\n",
        "rows, cols = 4, 4  # Define grid dimensions\n",
        "\n",
        "# Define mean and std for reverse normalization\n",
        "mean = np.array([0.5, 0.5, 0.5])\n",
        "std = np.array([0.5, 0.5, 0.5])\n",
        "\n",
        "for i in range(1, rows * cols + 1):\n",
        "    random_idx = torch.randint(0, len(train_data), size=[1]).item()  # Random index\n",
        "    img, label = train_data[random_idx]  # Get image and label\n",
        "\n",
        "    # Reverse normalization\n",
        "    img = img.permute(1, 2, 0).numpy()  # Convert to [H, W, C]\n",
        "    img = (img * std) + mean  # Undo normalization\n",
        "    img = np.clip(img, 0, 1)  # Ensure values are in [0, 1]\n",
        "\n",
        "    # Add a subplot for each image\n",
        "    ax = fig.add_subplot(rows, cols, i)\n",
        "    ax.imshow(img)  # Plot the image\n",
        "    ax.set_title(class_names[label])  # Set the title\n",
        "    ax.axis(\"off\")  # Remove axes\n",
        "\n",
        "plt.tight_layout()  # Adjust subplot spacing\n",
        "plt.show()  # Display the figure\n"
      ],
      "metadata": {
        "id": "BJ7opgCB39VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Image Shape: {image.shape}\")\n",
        "print(f\"Image Label: {class_names[label]}\")"
      ],
      "metadata": {
        "id": "hcK72k9R7MgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get an image and label\n",
        "image, label = train_data[0]\n",
        "\n",
        "# Print the shape of the image tensor\n",
        "print(f\"Image Shape: {image.shape}\")  # Should be [3, 32, 32]\n",
        "\n",
        "# Rearrange dimensions from [channels, height, width] to [height, width, channels]\n",
        "image = image.permute(1, 2, 0)  # [3, 32, 32] -> [32, 32, 3]\n",
        "\n",
        "# Plot the image\n",
        "plt.imshow(image)\n",
        "plt.title(class_names[label])\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MDB5Kcvn71rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# Plot more images\n",
        "torch.manual_seed(42)  # For reproducibility\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "rows, cols = 4, 4\n",
        "\n",
        "for i in range(1, rows * cols + 1):\n",
        "    random_idx = torch.randint(0, len(train_data), size=[1]).item()  # Random index\n",
        "    img, label = train_data[random_idx]  # Get image and label\n",
        "\n",
        "    # Rearrange dimensions from [3, 32, 32] to [32, 32, 3]\n",
        "    img = img.permute(1, 2, 0)\n",
        "\n",
        "    # Add subplot\n",
        "    ax = fig.add_subplot(rows, cols, i)\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(class_names[label])\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3MDzeUft8kzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WMvkXWrY_QEv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}